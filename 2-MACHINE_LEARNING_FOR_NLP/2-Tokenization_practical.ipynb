{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = '''\n",
    "Modi was born and raised in Vadnagar in northeastern \n",
    "Gujarat, where he completed his secondary education. \n",
    "He was introduced to the RSS at the age of eight. \n",
    "At the age of 18, he was married to Jashodaben Modi, \n",
    "whom he abandoned soon after, only publicly acknowledging her four \n",
    "decades later when legally required to do so.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nModi was born and raised in Vadnagar in northeastern \\nGujarat, where he completed his secondary education. \\nHe was introduced to the RSS at the age of eight. \\nAt the age of 18, he was married to Jashodaben Modi, \\nwhom he abandoned soon after, only publicly acknowledging her four \\ndecades later when legally required to do so.\\n'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "['\\nModi was born and raised in Vadnagar in northeastern \\nGujarat, where he completed his secondary education.', 'He was introduced to the RSS at the age of eight.', 'At the age of 18, he was married to Jashodaben Modi, \\nwhom he abandoned soon after, only publicly acknowledging her four \\ndecades later when legally required to do so.']\n"
     ]
    }
   ],
   "source": [
    "# Tokenization\n",
    "from nltk.tokenize import sent_tokenize # paragraph into sentence\n",
    "documents = sent_tokenize(corpus)\n",
    "print(type(documents))\n",
    "print(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Modi', 'was', 'born', 'and', 'raised', 'in', 'Vadnagar', 'in', 'northeastern', 'Gujarat', ',', 'where', 'he', 'completed', 'his', 'secondary', 'education', '.', 'He', 'was', 'introduced', 'to', 'the', 'RSS', 'at', 'the', 'age', 'of', 'eight', '.', 'At', 'the', 'age', 'of', '18', ',', 'he', 'was', 'married', 'to', 'Jashodaben', 'Modi', ',', 'whom', 'he', 'abandoned', 'soon', 'after', ',', 'only', 'publicly', 'acknowledging', 'her', 'four', 'decades', 'later', 'when', 'legally', 'required', 'to', 'do', 'so', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize # Paragraph into words tokenize\n",
    "words = word_tokenize(corpus)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Modi', 'was', 'born', 'and', 'raised', 'in', 'Vadnagar', 'in', 'northeastern', 'Gujarat', ',', 'where', 'he', 'completed', 'his', 'secondary', 'education', '.']\n",
      "['He', 'was', 'introduced', 'to', 'the', 'RSS', 'at', 'the', 'age', 'of', 'eight', '.']\n",
      "['At', 'the', 'age', 'of', '18', ',', 'he', 'was', 'married', 'to', 'Jashodaben', 'Modi', ',', 'whom', 'he', 'abandoned', 'soon', 'after', ',', 'only', 'publicly', 'acknowledging', 'her', 'four', 'decades', 'later', 'when', 'legally', 'required', 'to', 'do', 'so', '.']\n"
     ]
    }
   ],
   "source": [
    "for sentence in documents:\n",
    "    print(word_tokenize(sentence)) # Sentence into words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'M o d i   w a s   b o r n   a n d   r a i s e d   i n   V a d n a g a r   i n   n o r t h e a s t e r n   \\n G u j a r a t,   w h e r e   h e   c o m p l e t e d   h i s   s e c o n d a r y   e d u c a t i o n .   \\n H e   w a s   i n t r o d u c e d   t o   t h e   R S S   a t   t h e   a g e   o f   e i g h t .   \\n A t   t h e   a g e   o f   1 8,   h e   w a s   m a r r i e d   t o   J a s h o d a b e n   M o d i,   \\n w h o m   h e   a b a n d o n e d   s o o n   a f t e r,   o n l y   p u b l i c l y   a c k n o w l e d g i n g   h e r   f o u r   \\n d e c a d e s   l a t e r   w h e n   l e g a l l y   r e q u i r e d   t o   d o   s o.'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import TreebankWordDetokenizer\n",
    "tokenizer = TreebankWordDetokenizer()\n",
    "tokenizer.tokenize(corpus)\n",
    " \n",
    "# fullstop will not be treated as a separated word"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtual_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
