{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph = '''Before you can begin to determine what the composition \n",
    "of a particular paragraph will be, you must first decide \n",
    "on an argument and a working thesis statement for your \n",
    "paper. What is the most important idea that you are trying \n",
    "to convey to your reader? The information in each paragraph\n",
    "must be related to that idea. In other words, your paragraphs \n",
    "should remind your reader that there is a recurrent relationship\n",
    "between your thesis and the information in each paragraph. \n",
    "A working thesis functions like a seed from which your paper, \n",
    "and your ideas, will grow. The whole process is an organic one—a \n",
    "natural progression from a seed to a full-blown paper where \n",
    "there are direct, familial relationships between all of the ideas \n",
    "in the paper.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize # paragraph into sentence\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "documents = sent_tokenize(paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Before', 'IN'), ('begin', 'JJ'), ('determine', 'JJ'), ('composition', 'NN'), ('particular', 'JJ'), ('paragraph', 'NN'), (',', ','), ('must', 'MD'), ('first', 'RB'), ('decide', 'VB'), ('argument', 'NN'), ('working', 'VBG'), ('thesis', 'NN'), ('statement', 'NN'), ('paper', 'NN'), ('.', '.')]\n",
      "[('What', 'WP'), ('important', 'JJ'), ('idea', 'NN'), ('trying', 'VBG'), ('convey', 'JJ'), ('reader', 'NN'), ('?', '.')]\n",
      "[('The', 'DT'), ('information', 'NN'), ('paragraph', 'NN'), ('must', 'MD'), ('related', 'VBN'), ('idea', 'NN'), ('.', '.')]\n",
      "[('In', 'IN'), ('words', 'NNS'), (',', ','), ('paragraphs', 'NN'), ('remind', 'NN'), ('reader', 'NN'), ('recurrent', 'NN'), ('relationship', 'NN'), ('thesis', 'NN'), ('information', 'NN'), ('paragraph', 'NN'), ('.', '.')]\n",
      "[('A', 'DT'), ('working', 'JJ'), ('thesis', 'NN'), ('functions', 'NNS'), ('like', 'IN'), ('seed', 'NN'), ('paper', 'NN'), (',', ','), ('ideas', 'NNS'), (',', ','), ('grow', 'NN'), ('.', '.')]\n",
      "[('The', 'DT'), ('whole', 'JJ'), ('process', 'NN'), ('organic', 'JJ'), ('one—a', 'IN'), ('natural', 'JJ'), ('progression', 'NN'), ('seed', 'NN'), ('full-blown', 'JJ'), ('paper', 'NN'), ('direct', 'NN'), (',', ','), ('familial', 'JJ'), ('relationships', 'NNS'), ('ideas', 'NNS'), ('paper', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "# We will find out the POS tag\n",
    "for i in range(len(documents)):\n",
    "    words = word_tokenize(documents[i])\n",
    "    words = [word for word in words if word not in set(stopwords.words('english'))]\n",
    "    p_tag = nltk.pos_tag(words)\n",
    "    print(p_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtual_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
