{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.document_loaders.text.TextLoader at 0x7a66742fbe50>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Reading A text Data\n",
    "\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "loader = TextLoader('speech.txt')\n",
    "loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'speech.txt'}, page_content='In computing, plain text is a loose term for data (e.g. file contents) that represent only characters of readable material but not its graphical representation nor other objects (floating-point numbers, images, etc.). It may also include a limited number of \"whitespace\" characters that affect simple arrangement of text, such as spaces, line breaks, or tabulation characters. Plain text is different from formatted text, where style information is included; from structured text, where structural parts of the document such as paragraphs, sections, and the like are identified; and from binary files in which some portions must be interpreted as binary objects (encoded integers, real numbers, images, etc.).\\n\\nThe term is sometimes used quite loosely, to mean files that contain only \"readable\" content (or just files with nothing that the speaker does not prefer). For example, that could exclude any indication of fonts or layout (such as markup, markdown, or even tabs); characters such as curly quotes, non-breaking spaces, soft hyphens, em dashes, and/or ligatures; or other things.\\n\\nIn principle, plain text can be in any encoding, but occasionally the term is taken to imply ASCII. As Unicode-based encodings such as UTF-8 and UTF-16 become more common, that usage may be shrinking.\\n\\nPlain text is also sometimes used only to exclude \"binary\" files: those in which at least some parts of the file cannot be correctly interpreted via the character encoding in effect. For example, a file or string consisting of \"hello\" (in any encoding), following by 4 bytes that express a binary integer that is not a character, is a binary file. Converting a plain text file to a different character encoding does not change the meaning of the text, as long as the correct character encoding is used. However, converting a binary file to a different format may alter the interpretation of the non-textual data.\\n\\nPlain text and rich text\\nAccording to The Unicode Standard:[1]\\n\\n\"Plain text is a pure sequence of character codes; plain Un-encoded text is therefore a sequence of Unicode character codes.\\nIn contrast, styled text, also known as rich text, is any text representation containing plain text plus added information such as a language identifier, font size, color, hypertext links, and so on.\\nSGML, RTF, HTML, XML, and TeX are examples of rich text fully represented as plain text streams, interspersing plain text data with sequences of characters that represent the additional data structures.\"\\nAccording to other definitions, however, files that contain markup or other meta-data are generally considered plain text, so long as the markup is also in a directly human-readable form (as in HTML, XML, and so on). Thus, representations such as SGML, RTF, HTML, XML, wiki markup, and TeX, as well as nearly all programming language source code files, are considered plain text. The particular content is irrelevant to whether a file is plain text. For example, an SVG file can express drawings or even bitmapped graphics, but is still plain text.\\n\\nThe use of plain text rather than binary files enables files to survive much better \"in the wild\", in part by making them largely immune to computer architecture incompatibilities. For example, with all data encoded as UTF-8 text, all the problems of endianness can be avoided.\\n\\nUsage\\nThe purpose of using plain text today is primarily independence from programs that require their very own special encoding or formatting or file format. Plain text files can be opened, read, and edited with ubiquitous text editors and utilities.\\n\\nA command-line interface allows people to give commands in plain text and get a response, also typically in plain text.\\n\\nMany other computer programs are also capable of processing or creating plain text, such as countless programs in DOS, Windows, classic Mac OS, and Unix and its kin; as well as web browsers (a few browsers such as Lynx and the Line Mode Browser produce only plain text for display) and other e-text readers.\\n\\nPlain text files are almost universal in programming; a source code file containing instructions in a programming language is almost always a plain text file. Plain text is also commonly used for configuration files, which are read for saved settings at the startup of a program.\\n\\nPlain text is used for much e-mail.\\n\\nA comment, a \".txt\" file, or a TXT Record generally contains only plain text (without formatting) intended for humans to read.\\n\\nThe best format for storing knowledge persistently is plain text, rather than some binary format.[2]\\n\\n')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Containt will be convert into document by\n",
    "text_document = loader.load()\n",
    "text_document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'PyFPDF 1.7.2 http://pyfpdf.googlecode.com/', 'creator': 'PyPDF', 'creationdate': 'D:20250414102918', 'source': 'Mohit_Sarawgi_Frontend_Cover_Letter.pdf', 'total_pages': 2, 'page': 0, 'page_label': '1'}, page_content=\"Mohit Sarawgi - Frontend Engineer Cover Letter\\nMohit Sarawgi\\nJabalpur, Madhya Pradesh\\nhttps://www.linkedin.com/in/mohitsarawgi07/\\nmohitsarawgi07@gmail.com\\nDate: April 14, 2025\\nSubject: Application for Frontend Engineer Role - Benchmark Team\\nDear Hiring Team,\\nI'm writing to express my interest in the Frontend Engineer position on your Benchmark team. As\\nsomeone who's deeply passionate about clean UI, strong design principles, and building tools that\\nactually make a difference, this role instantly stood out to me.\\nI recently completed my degree in Machine Learning and have been actively involved in building\\nfrontend projects where design meets performance. Most recently, I've worked on an AI-based\\nSaaS platform using Next.js, MongoDB, and OpenAI - with a special focus on reducing loading\\ntimes by 80% while delivering a highly interactive, customizable UI. Through this, I learned how\\nimportant a solid design system is for both designers and developers to move faster without\\ncompromising on quality.\\nWhile I have 0-2 years of formal experience, I've built, tested, and debugged multiple real-world\\nprojects, both independently and in teams. I'm highly comfortable working with JavaScript,\\nTypeScript, and Angular, and I also bring working knowledge of Web APIs, modern HTML/CSS, and\\nPage 1\"),\n",
       " Document(metadata={'producer': 'PyFPDF 1.7.2 http://pyfpdf.googlecode.com/', 'creator': 'PyPDF', 'creationdate': 'D:20250414102918', 'source': 'Mohit_Sarawgi_Frontend_Cover_Letter.pdf', 'total_pages': 2, 'page': 1, 'page_label': '2'}, page_content=\"Mohit Sarawgi - Frontend Engineer Cover Letter\\ntesting best practices. I care a lot about writing accessible, maintainable code, and I love\\ncollaborating with designers to make sure we're not just functional, but delightful.\\nWhat excites me about your Benchmark team is the intersection of engineering and design - I'd love\\nto contribute to a system that not only powers UI but also empowers teams to build with consistency,\\nspeed, and confidence. I believe my hands-on experience, attention to detail, and eagerness to\\nkeep learning make me a strong fit for this role.\\nThank you for considering my application. I'd love the opportunity to connect and share more about\\nhow I can contribute to your team. Looking forward to hearing from you!\\nWarm regards,\\nMohit Sarawgi\\nPage 2\")]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Reading A PDF file\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "pdfloader = PyPDFLoader('Mohit_Sarawgi_Frontend_Cover_Letter.pdf')\n",
    "pdf_document = pdfloader.load()\n",
    "pdf_document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.documents.base.Document"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pdf_document[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Web Based Loader\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "webloader = WebBaseLoader(web_paths=(\"https://en.wikipedia.org/wiki/Plain_text\",),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://en.wikipedia.org/wiki/Plain_text', 'title': 'Plain text - Wikipedia', 'language': 'en'}, page_content='\\n\\n\\n\\nPlain text - Wikipedia\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJump to content\\n\\n\\n\\n\\n\\n\\n\\nMain menu\\n\\n\\n\\n\\n\\nMain menu\\nmove to sidebar\\nhide\\n\\n\\n\\n\\t\\tNavigation\\n\\t\\n\\n\\nMain pageContentsCurrent eventsRandom articleAbout WikipediaContact us\\n\\n\\n\\n\\n\\n\\t\\tContribute\\n\\t\\n\\n\\nHelpLearn to editCommunity portalRecent changesUpload fileSpecial pages\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAppearance\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nDonate\\n\\nCreate account\\n\\nLog in\\n\\n\\n\\n\\n\\n\\n\\n\\nPersonal tools\\n\\n\\n\\n\\n\\nDonate Create account Log in\\n\\n\\n\\n\\n\\n\\t\\tPages for logged out editors learn more\\n\\n\\n\\nContributionsTalk\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nContents\\nmove to sidebar\\nhide\\n\\n\\n\\n\\n(Top)\\n\\n\\n\\n\\n\\n1\\nPlain text and rich text\\n\\n\\n\\n\\n\\n\\n\\n\\n2\\nUsage\\n\\n\\n\\n\\n\\n\\n\\n\\n3\\nEncoding\\n\\n\\n\\n\\nToggle Encoding subsection\\n\\n\\n\\n\\n\\n3.1\\nCharacter encodings\\n\\n\\n\\n\\n\\n\\n\\n\\n3.2\\nControl codes\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n4\\nSee also\\n\\n\\n\\n\\n\\n\\n\\n\\n5\\nReferences\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nToggle the table of contents\\n\\n\\n\\n\\n\\n\\n\\nPlain text\\n\\n\\n\\n31 languages\\n\\n\\n\\n\\nالعربية閩南語 / Bân-lâm-gúБеларускаяCatalàČeštinaDeutschΕλληνικάEspañolEsperantoEuskaraفارسیFrançais한국어Bahasa IndonesiaItalianoBahasa MelayuNederlands日本語Norsk bokmålPortuguêsRomânăРусскийSimple EnglishکوردیSvenskaไทยTürkçeУкраїнськаTiếng Việt粵語中文\\n\\nEdit links\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nArticleTalk\\n\\n\\n\\n\\n\\nEnglish\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nReadEditView history\\n\\n\\n\\n\\n\\n\\n\\nTools\\n\\n\\n\\n\\n\\nTools\\nmove to sidebar\\nhide\\n\\n\\n\\n\\t\\tActions\\n\\t\\n\\n\\nReadEditView history\\n\\n\\n\\n\\n\\n\\t\\tGeneral\\n\\t\\n\\n\\nWhat links hereRelated changesUpload filePermanent linkPage informationCite this pageGet shortened URLDownload QR code\\n\\n\\n\\n\\n\\n\\t\\tPrint/export\\n\\t\\n\\n\\nDownload as PDFPrintable version\\n\\n\\n\\n\\n\\n\\t\\tIn other projects\\n\\t\\n\\n\\nWikidata item\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAppearance\\nmove to sidebar\\nhide\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nFrom Wikipedia, the free encyclopedia\\n\\n\\nTerm for computer data consisting only of unformatted characters of readable material\\nFor the cryptography meaning, see Plaintext. For other uses, see Text (disambiguation).\\nThis article needs additional citations for verification. Please help improve this article by adding citations to reliable sources. Unsourced material may be challenged and removed.Find sources:\\xa0\"Plain text\"\\xa0–\\xa0news\\xa0· newspapers\\xa0· books\\xa0· scholar\\xa0· JSTOR (August 2012) (Learn how and when to remove this message)\\nText file with portion of The Human Side of Animals by Royal Dixon, displayed by the command cat in an xterm window\\nIn computing, plain text is a loose term for data (e.g. file contents) that represent only characters of readable material but not its graphical representation nor other objects (floating-point numbers, images, etc.). It may also include a limited number of \"whitespace\" characters that affect simple arrangement of text, such as spaces, line breaks, or tabulation characters. Plain text is different from formatted text, where style information is included; from structured text, where structural parts of the document such as paragraphs, sections, and the like are identified; and from binary files in which some portions must be interpreted as binary objects (encoded integers, real numbers, images, etc.).\\nThe term is sometimes used quite loosely, to mean files that contain only \"readable\" content (or just files with nothing that the speaker does not prefer). For example, that could exclude any indication of fonts or layout (such as markup, markdown, or even tabs); characters such as curly quotes, non-breaking spaces, soft hyphens, em dashes, and/or ligatures; or other things.\\nIn principle, plain text can be in any encoding, but occasionally the term is taken to imply ASCII. As Unicode-based encodings such as UTF-8 and UTF-16 become more common, that usage may be shrinking.\\nPlain text is also sometimes used only to exclude \"binary\" files: those in which at least some parts of the file cannot be correctly interpreted via the character encoding in effect. For example, a file or string consisting of \"hello\" (in any encoding), following by 4 bytes that express a binary integer that is not a character, is a binary file. Converting a plain text file to a different character encoding does not change the meaning of the text, as long as the correct character encoding is used. However, converting a binary file to a different format may alter the interpretation of the non-textual data.\\n\\n\\nPlain text and rich text[edit]\\nAccording to The Unicode Standard:[1]\\n\\n\"Plain text is a pure sequence of character codes; plain Un-encoded text is therefore a sequence of Unicode character codes.\\nIn contrast, styled text, also known as rich text, is any text representation containing plain text plus added information such as a language identifier, font size, color, hypertext links, and so on.\\nSGML, RTF, HTML, XML, and TeX are examples of rich text fully represented as plain text streams, interspersing plain text data with sequences of characters that represent the additional data structures.\"\\nAccording to other definitions, however, files that contain markup or other meta-data are generally considered plain text, so long as the markup is also in a directly human-readable form (as in HTML, XML, and so on). Thus, representations such as SGML, RTF, HTML, XML, wiki markup, and TeX, as well as nearly all programming language source code files, are considered plain text. The particular content is irrelevant to whether a file is plain text. For example, an SVG file can express drawings or even bitmapped graphics, but is still plain text.\\nThe use of plain text rather than binary files enables files to survive much better \"in the wild\", in part by making them largely immune to computer architecture incompatibilities. For example, with all data encoded as UTF-8 text, all the problems of endianness can be avoided.\\n\\nUsage[edit]\\nThe purpose of using plain text today is primarily independence from programs that require their very own special encoding or formatting or file format. Plain text files can be opened, read, and edited with ubiquitous text editors and utilities.\\nA command-line interface allows people to give commands in plain text and get a response, also typically in plain text.\\nMany other computer programs are also capable of processing or creating plain text, such as countless programs in DOS, Windows, classic Mac OS, and Unix and its kin; as well as web browsers (a few browsers such as Lynx and the Line Mode Browser produce only plain text for display) and other e-text readers.\\nPlain text files are almost universal in programming; a source code file containing instructions in a programming language is almost always a plain text file. Plain text is also commonly used for configuration files, which are read for saved settings at the startup of a program.\\nPlain text is used for much e-mail.\\nA comment, a \".txt\" file, or a TXT Record generally contains only plain text (without formatting) intended for humans to read.\\nThe best format for storing knowledge persistently is plain text, rather than some binary format.[2]\\n\\nEncoding[edit]\\nCharacter encodings[edit]\\nThis section does not cite any sources. Please help improve this section by adding citations to reliable sources. Unsourced material may be challenged and removed. (December 2023) (Learn how and when to remove this message)\\nMain article: Character encoding\\nBefore the early 1960s, computers were mainly used for number-crunching rather than for text, and memory was extremely expensive. Computers often allocated only 6 bits for each character, permitting only 64 characters—assigning codes for A-Z, a-z, and 0-9 would leave only 2 codes: nowhere near enough. Most computers opted not to support lower-case letters. Thus, early text projects such as Roberto Busa\\'s Index Thomisticus, the Brown Corpus, and others had to resort to conventions such as keying an asterisk preceding letters actually intended to be upper-case.\\nFred Brooks of IBM argued strongly for going to 8-bit bytes, because someday people might want to process text, and won. Although IBM used EBCDIC, most text from then on came to be encoded in ASCII, using values from 0 to 31 for (non-printing) control characters, and values from 32 to 127 for graphic characters such as letters, digits, and punctuation. Most machines stored characters in 8 bits rather than 7, ignoring the remaining bit or using it as a checksum.\\nThe near-ubiquity of ASCII was a great help, but failed to address international and linguistic concerns. The dollar-sign (\"$\") was not as useful in England, and the accented characters used in Spanish, French, German, Portuguese, Italian and many other languages were entirely unavailable in ASCII (not to mention characters used in Greek, Russian, and most Eastern languages). Many individuals, companies, and countries defined extra characters as needed—often reassigning control characters, or using values in the range from 128 to 255. Using values above 128 conflicts with using the 8th bit as a checksum, but the checksum usage gradually died out.\\nThese additional characters were encoded differently in different countries, making texts impossible to decode without figuring out the originator\\'s rules. For instance, a browser might display ¬A rather than ` if it tried to interpret one character set as another. The International Organization for Standardization (ISO) eventually developed several code pages under ISO 8859, to accommodate various languages. The first of these (ISO 8859-1) is also known as \"Latin-1\", and covers the needs of most (not all) European languages that use Latin-based characters (there was not quite enough room to cover them all). ISO 2022 then provided conventions for \"switching\" between different character sets in mid-file. Many other organisations developed variations on these, and for many years Windows and Macintosh computers used incompatible variations.\\nThe text-encoding situation became more and more complex, leading to efforts by ISO and by the Unicode Consortium to develop a single, unified character encoding that could cover all known (or at least all currently known) languages. After some conflict,[3] these efforts were unified. Unicode currently allows for 1,114,112 code values, and assigns codes covering nearly all modern text writing systems, as well as many historical ones, and for many non-linguistic characters such as printer\\'s dingbats, mathematical symbols, etc.\\nText is considered plain text regardless of its encoding. To properly understand or process it the recipient must know (or be able to figure out) what encoding was used; however, they need not know anything about the computer architecture that was used, or about the binary structures defined by whatever program (if any) created the data.\\nPerhaps the most common way of explicitly stating the specific encoding of plain text is with a MIME type.\\nFor email and HTTP, the default MIME type is \"text/plain\" -- plain text without markup.\\nAnother MIME type often used in both email and HTTP is \"text/html; charset=UTF-8\" -- plain text represented using the UTF-8 character encoding with HTML markup.\\nAnother common MIME type is \"application/json\" -- plain text represented using the UTF-8 character encoding with JSON markup.\\nWhen a document is received without any explicit indication of the character encoding, some applications use charset detection to attempt to guess what encoding was used.\\n\\nControl codes[edit]\\nMain article: C0 and C1 control codes\\nASCII reserves the first 32 codes (numbers 0–31 decimal) for control characters known as the \"C0 set\": codes originally intended not to represent printable information, but rather to control devices (such as printers) that make use of ASCII, or to provide meta-information about data streams such as those stored on magnetic tape. They include common characters like the newline and the tab character.\\nIn 8-bit character sets such as Latin-1 and the other ISO 8859 sets, the first 32 characters of the \"upper half\" (128 to 159) are also control codes, known as the \"C1 set\". They are rarely used directly; when they turn up in documents which are ostensibly in an ISO 8859 encoding, their code positions generally refer instead to the characters at that position in a proprietary, system-specific encoding, such as Windows-1252 or Mac OS Roman, that use the codes to instead provide additional graphic characters.\\n\\nMain article: Unicode control characters\\nUnicode defines additional control characters, including bi-directional text direction override characters (used to explicitly mark right-to-left writing inside left-to-right writing and the other way around) and variation selectors to select alternate forms of CJK ideographs, emoji and other characters.\\n\\nSee also[edit]\\nBinary data\\nBinary file\\nBinary protocol\\nSource code\\nText file\\nText-based protocol\\nLine wrap and word wrap\\nReferences[edit]\\n\\n\\n^ \"The Unicode Standard, version 14.0\" (PDF). pp.\\xa018–19.\\n\\n^ \\nAndrew Hunt, David Thomas.\\n\"The Pragmatic Programmer\".\\n1999.\\nChapter 14: \"The Power of Plain Text\".\\np. 73.\\n\\n^ \"ISO/Unicode Merger: Ed Hart Memo\". www.unicode.org. Retrieved 2024-10-21.\\n\\n\\nvteData typesUninterpreted\\nBit\\nByte\\nTrit\\nTryte\\nWord\\nBit array\\nNumeric\\nArbitrary-precision or bignum\\nComplex\\nDecimal\\nFixed point\\nBlock floating point\\nFloating point\\nReduced precision\\nMinifloat\\nHalf precision\\nbfloat16\\nSingle precision\\nDouble precision\\nQuadruple precision\\nOctuple precision\\nExtended precision\\nLong double\\nInteger\\nsignedness\\nInterval\\nRational\\nPointer\\nAddress\\nphysical\\nvirtual\\nReference\\nText\\nCharacter\\nString\\nnull-terminated\\nComposite\\nAlgebraic data type\\ngeneralized\\nArray\\nAssociative array\\nClass\\nDependent\\nEquality\\nInductive\\nIntersection\\nList\\nObject\\nmetaobject\\nOption type\\nProduct\\nRecord or Struct\\nRefinement\\nSet\\nUnion\\ntagged\\nOther\\nBoolean\\nBottom type\\nCollection\\nEnumerated type\\nException\\nFunction type\\nOpaque data type\\nRecursive data type\\nSemaphore\\nStream\\nStrongly typed identifier\\nTop type\\nType class\\nEmpty type\\nUnit type\\nVoid\\nRelatedtopics\\nAbstract data type\\nBoxing\\nData structure\\nGeneric\\nKind\\nmetaclass\\nParametric polymorphism\\nPrimitive data type\\nInterface\\nSubtyping\\nType constructor\\nType conversion\\nType system\\nType theory\\nVariable\\n\\n\\n\\n\\n\\nRetrieved from \"https://en.wikipedia.org/w/index.php?title=Plain_text&oldid=1294070315\"\\nCategories: Text file formatsOpen formatsHidden categories: Articles with short descriptionShort description is different from WikidataArticles needing additional references from August 2012All articles needing additional referencesArticles needing additional references from December 2023\\n\\n\\n\\n\\n\\n\\n This page was last edited on 5 June 2025, at 11:42\\xa0(UTC).\\nText is available under the Creative Commons Attribution-ShareAlike 4.0 License;\\nadditional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy. Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc., a non-profit organization.\\n\\n\\nPrivacy policy\\nAbout Wikipedia\\nDisclaimers\\nContact Wikipedia\\nCode of Conduct\\nDevelopers\\nStatistics\\nCookie statement\\nMobile view\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nToggle the table of contents\\n\\n\\n\\n\\n\\n\\n\\nPlain text\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n31 languages\\n\\n\\nAdd topic\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "webloader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Arxiv\n",
    "from langchain_community.document_loaders import ArxivLoader\n",
    "docs = ArxivLoader(query=\"1605.08386\", load_max_docs= 2).load()\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'Published': '2016-05-26', 'Title': 'Heat-bath random walks with Markov bases', 'Authors': 'Caprice Stanley, Tobias Windisch', 'Summary': 'Graphs on lattice points are studied whose edges come from a finite set of\\nallowed moves of arbitrary length. We show that the diameter of these graphs on\\nfibers of a fixed integer matrix can be bounded from above by a constant. We\\nthen study the mixing behaviour of heat-bath random walks on these graphs. We\\nalso state explicit conditions on the set of moves so that the heat-bath random\\nwalk, a generalization of the Glauber dynamics, is an expander in fixed\\ndimension.'}, page_content='arXiv:1605.08386v1  [math.CO]  26 May 2016\\nHEAT-BATH RANDOM WALKS WITH MARKOV BASES\\nCAPRICE STANLEY AND TOBIAS WINDISCH\\nAbstract. Graphs on lattice points are studied whose edges come from a ﬁnite set of\\nallowed moves of arbitrary length. We show that the diameter of these graphs on ﬁbers of a\\nﬁxed integer matrix can be bounded from above by a constant. We then study the mixing\\nbehaviour of heat-bath random walks on these graphs. We also state explicit conditions\\non the set of moves so that the heat-bath random walk, a generalization of the Glauber\\ndynamics, is an expander in ﬁxed dimension.\\nContents\\n1.\\nIntroduction\\n1\\n2.\\nGraphs and statistics\\n3\\n3.\\nBounds on the diameter\\n4\\n4.\\nHeat-bath random walks\\n8\\n5.\\nAugmenting Markov bases\\n14\\nReferences\\n19\\n1. Introduction\\nA ﬁber graph is a graph on the ﬁnitely many lattice points F ⊂Zd of a polytope where\\ntwo lattice points are connected by an edge if their diﬀerence lies in a ﬁnite set of allowed\\nmoves M ⊂Zd. The implicit structure of these graphs makes them a useful tool to explore\\nthe set of lattice points randomly: At the current lattice point u ∈F, an element m ∈±M\\nis sampled and the random walk moves along m if u + m ∈F and stays at u otherwise.\\nThe corresponding Markov chain is irreducible if the underlying ﬁber graph is connected and\\nthe set M is called a Markov basis for F in this case. This paper investigates the heat-bath\\nversion of this random walk: At the current lattice point u ∈F, we sample m ∈M and move\\nto a random element in the integer ray (u + Z · m) ∩F. The authors of [6] discovered that\\nthis random walk can be seen as a discrete version of the hit-and-run algorithm [15, 26, 16]\\nthat has been used frequently to sample from all the points of a polytope – not only from its\\nlattice points. The popularity of the continuous version of the hit-and-run algorithm has not\\nspread to its discrete analog, and not much is known about its mixing behaviour. One reason\\nis that it is already challenging to guarantee that all points in the underlying set F can be\\nDate: September 12, 2018.\\n2010 Mathematics Subject Classiﬁcation. Primary: 05C81, Secondary: 37A25, 11P21.\\nKey words and phrases. Heat-bath random walks, sampling, lattice points, Markov bases.\\n1\\n2\\nCAPRICE STANLEY AND TOBIAS WINDISCH\\nreached by a random walk that uses moves from M, whereas for the continuous version, a\\nrandom sampling from the unit sphere suﬃces. However, in many situations where a Markov\\nbasis is known, the heat-bath random walk is evidently fast. For instance, it was shown in [3]\\nthat the heat-bath random walk on contingency tables mixes rapidly when the number of\\ncolumns is ﬁxed. To work around the connectedness issue, a discrete hit-and-run algorithm\\nwas introduced in [1] for arbitrary ﬁnite sets F ⊂Zd. At each step in this random walk, a\\nsubordinate and unrestricted random walk starts at the current lattice point u ∈F and uses\\nthe unit vectors to collect a set of proposals S ⊂Zd. The random walk then moves from u\\nto a random point in S ∩F.\\nRandom walks of the heat-bath type, such as the one presented above, have been studied\\nrecently in [8] in a more general context. In this paper, we explore the mixing behaviour of\\nheat-bath random walks on the lattice points of polytopes with Markov bases. Throughout,\\nwe assume that a Markov basis has been found already and refer to the relevant literature\\nfor their computation [24, 25, 11, 17, 10, 21]. We call the underlying graph of the heat-bath\\nrandom walk a compressed ﬁber graph (Deﬁnition 2.5) and determine in Section 3 bounds on\\nits graph-diameter. We prove that for any A ∈Zm×d with kerZ(A)∩Nd = {0}, the diameter of\\ncompressed ﬁber graphs on {u ∈Nd : Au = b} that use a ﬁxed Markov bases M ⊂kerZ(A) is\\nbounded from above by a constant as b varies (Theorem 3.15). In contrast, we show that the\\ndiameter of conventional ﬁber graphs grow linearly under a dilation of the underlying polytope\\n(Remark 3.9). This gives rise to slow mixing results for conventional ﬁber walks as observed\\nin [27]. In Section 4, we study in more detail the combinatorial and analytical structure\\nof the transition matrices of heat-bath random walks on lattice points and prove upper and\\nlower bounds on their second largest eigenvalues. We also discuss how the distribution on the\\nmoves M aﬀects the speed of convergence (Example 4.21). Theorem 5.8 establishes with the\\ncanonical path approach from [23] an upper bound on the second largest eigenvalue when the\\nMarkov basis is augmenting (Deﬁnition 5.1) and the stationary distribution is uniform. From\\nthat, we conclude fast mixing results for random walks on lattice points in ﬁxed dimension.\\nAcknowledgements. CS was partially supported by the US National Science Foundation\\n(DMS 0954865). TW gratefully acknowledges the support received from the German National\\nAcademic Foundation.\\nConventions and Notation. The natural numbers are N := {0, 1, 2, . . .} and for any N ∈N,\\nN>N := {n ∈N : n > N} and N≥N := {N} ∪N>N. For n ∈N>0, let [n] := {1, . . . , n}. Let\\nM ⊂Qd be a ﬁnite set, then Z·M := {λm : m ∈M, λ ∈Z} and NM is the aﬃne semigroup\\nin Zd generated by M. For an integer matrix A ∈Zm×d with columns a1, . . . , ad ∈Zm,\\nwe write NA := N{a1, . . . , ad}. A graph is always undirected and can have multiple loops.\\nThe distance of two nodes u, v which are contained in the same connected component of a\\ngraph G, i.e. the number of edges in a shortest path between u and v in G, is denoted by\\ndistG(u, v). We set distG(u, v) := ∞if u and v are disconnected. A mass function on a ﬁnite\\nset Ωis a map f : Ω→[0, 1] such that P\\nω∈Ωf(ω) = 1. A mass function f on Ωis positive\\nif f(ω) > 0 for all ω ∈Ω. A set F ⊂Zd is normal if it there exists a polytope P ⊂Qd such\\nthat P ∩Zd = F.\\nHEAT-BATH RANDOM WALKS WITH MARKOV BASES\\n3\\n2. Graphs and statistics\\nWe ﬁrst introduce the statistical framework in which this paper lives and recall important\\naspects of the interplay between graphs and statistics. A random walk on a graph G = (V, E)\\nis a map H : V × V →[0, 1] such that for all v ∈V , P\\nu∈V H(v, u) = 1 and such that\\nH(v, u) = 0 if {v, u} ̸∈E. When there is no ambiguity, we represent a random walk as an\\n|V | × |V |-matrix, for example when it is clear how the elements of V are ordered. Fix a\\nrandom walk H on G. Then H is irreducible if for all v, u ∈V there exists t ∈N such that\\nHt(v, u) > 0. The random walk H is reversible if there exists a mass function µ : V →[0, 1]\\nsuch that µ(u) · H(u, v) = µ(v) · H(v, u) for all u, v ∈V and symmetric if H is a symmetric\\nmap. A mass function π : V →[0, 1] is a stationary distribution of H if π ◦H = π. For\\nsymmetric random walks, the uniform distribution on V is always a stationary distribution.\\nIf |V | = n, then we denote the eigenvalues of H by 1 = λ1(H) ≥λ2(H) ≥· · · ≥λn(H) ≥−1\\nand we write λ(H) := max{λ2(H), −λn(H)} for the second largest eigenvalue modulus of H.\\nAny irreducible random walk has a unique stationary distribution [14, Corollary 1.17] and\\nλ(H) ∈[0, 1] measures the convergence rate: the smaller λ(H), the faster the convergence.\\nThe aim of this paper is to study random walks on lattice points that use a set of moves.\\nTypically, this is achieved by constructing a graph on the set of lattice points as follows\\n(compare to [7, Section 1.3] and [24, Chapter 5]).\\nDeﬁnition 2.1. Let F ⊂Zd be a ﬁnite set and M ⊂Zd. The graph F(M) is the graph on\\nF where two nodes u, v ∈F are adjacent if u −v ∈M or v −u ∈M.\\nA normal set F ⊂Zd is ﬁnite and satisﬁes F = convQ(F)∩Zd. A canonical class of normal\\nsets that arise in many applications, is given by the ﬁbers of an integer matrix:\\nDeﬁnition 2.2. Let A ∈Zm×d and b ∈NA. The set FA,b := {u ∈Nd : Au = b} is the b-ﬁber\\nof A. The collection of all ﬁbers of A is PA := {FA,b : b ∈NA}. For M ⊂kerZ(A), the graph\\nFA,b (M) is a ﬁber graph.\\nLet F, M ⊂Zd be ﬁnite. If the membership in F can be veriﬁed eﬃciently – for instance\\nwhen F is given implicitly by linear equations and inequalities – then it is possible to explore\\nF randomly using M as follows: At a given node v ∈F, a uniform element m ∈M is\\nselected. If v + m ∈M, then the random walk moves along m to v + m and if v + m ̸∈M,\\nthe we stay at v. Formally, we obtain the following random walk.\\nDeﬁnition 2.3. Let F ⊂Zd and M ⊂Zd be two ﬁnite sets. The simple walk is the random\\nwalk on F(M) where the probability to traverse between to adjacent nodes u and v is |±M|−1\\nand the probability to stay at a node u is |{m ∈±M : u + m ̸∈F}| · | ± M|−1.\\nThe simple walk is symmetric and hence the uniform distribution is a stationary distribu-\\ntion (see also [27, Section 2]). To ensure convergence, the random walk has to be irreducible,\\nthat is, the underlying graph has to be connected. The following deﬁnition is a slight adaption\\nof the generalized Markov basis as deﬁned in [21, Deﬁnition 1].\\nDeﬁnition 2.4. Let P be a collection of ﬁnite subsets of Zd. A ﬁnite set M ⊂Zd is a\\nMarkov basis of P, if for all F ∈P, F(M) is a connected graph.\\n4\\nCAPRICE STANLEY AND TOBIAS WINDISCH\\nWe refer to [6, Theorem 3.1] for a proof that for collections PA, a ﬁnite Markov basis\\nalways exists and can be computed with tools from commutative algebra (see also [11] for\\nmore on the computation of Markov bases). We now introduce a construction of graphs on\\nlattice points that also give rise to implementable random walks, but whose edges have far\\nmore reach.\\nDeﬁnition 2.5. Let F ⊂Zd and M ⊂Zd be ﬁnite sets. The compression of the graph\\nF(M) is the graph Fc(M) := F(Z · M).\\nFigure 1. Compressing graphs.\\nCompressing a graph F(M) preserves its connectedness: F(M) is connected if and only\\nif Fc(M) is connected.\\n3. Bounds on the diameter\\nIn general knowledge of the diameter of the graph underlying a Markov chain can provide\\ninformation about the mixing time. For random walks on ﬁber graphs, the chains which we\\nconsider, the underlying graph coincides with the ﬁber graph. In this section, we determine\\nlower and upper bounds on the diameter of ﬁber graphs and their compressed counterparts.\\nFor a ﬁnite set M ⊂Zd and any norm ∥· ∥on Rd, let ∥M∥:= maxm∈M ∥m∥.\\nLemma 3.1. Let F ⊂Zd and M ⊂Zd be ﬁnite sets, then\\ndiam(F(M)) ≥\\n1\\n∥M∥· max{∥u −v∥: u, v ∈F}.\\nProof. If F(M) is not connected, then the statement holds trivially, so assume that M is a\\nMarkov basis for F. Let u′, v′ ∈F such that ∥u′ −v′∥= max{∥u −v∥: u, v ∈F} and let\\nm1, . . . , mr ∈M so that u′ = v′+Pr\\ni=1 mi is a path of minimal length, then ∥u′−v′∥≤r·∥M∥\\nand the claim follows from diam(F(M)) ≥distF(M)(u′, v′) = r.\\n□\\nRemark 3.2. Let F ⊂Zd be a normal set. For all l ∈{−1, 0, 1}d and u, v ∈F we have\\n(u −v)T l ≤∥u −v∥1 and thus widthl(F) := max{(u −v)T l : u, v ∈F} ≤max{∥u −v∥1 :\\nu, v ∈F}. Suppose that u′, v′ ∈F are such that ∥u′ −v′∥1 = max{∥u −v∥1 : u, v ∈F} and\\nlet l′\\ni := sign(u′\\ni −v′\\ni) for i ∈[d], then\\n∥u′ −v′∥1 = (u′ −v′)T · l′ ≤widthl′(F) ≤max{∥u −v∥1 : u, v ∈F} = ∥u′ −v′∥1.\\nThe lattice width of F is width(F) := minl∈Zd widthl(F) and thus Lemma 3.1 gives\\n∥M∥1 · diam(F(M)) ≥width(F).\\nHEAT-BATH RANDOM WALKS WITH MARKOV BASES\\n5\\nDeﬁnition 3.3. Let P be a collection of ﬁnite subsets of Zd.\\nA ﬁnite set M ⊂Zd is\\nnorm-like for P if there exists a constant C ∈N such that for all F ∈P and all u, v ∈F,\\ndistF(M)(u, v) ≤C · ∥u −v∥. The set M is ∥· ∥-norm-reducing for P if for all F ∈P and all\\nu, v ∈F there exists m ∈M such that u + m ∈F and ∥u + m −v∥< ∥u −v∥.\\nThe property of being norm-like does not depend on the norm, whereas being norm-\\nreducing does.\\nNorm-reducing sets are always norm-like, and norm-like sets are in turn\\nalways Markov bases, but the reverse of both statements is false in general (Example 3.4 and\\nExample 3.5). For collections PA however, every Markov basis is norm-like (Proposition 3.7).\\nExample 3.4. For any n ∈N, consider the normal set Fn := ([2]×[n]×{0})∪{(2, n, 1)} with\\nthe Markov basis {(0, 1, 0), (0, 0, 1), (−1, 0, −1)}. The distance between (1, 1, 0) and (2, 1, 0)\\nin Fn(M) is 2n and thus M is not norm-like for {Fn : n ∈N} (see also Figure 2).\\nExample 3.5. Let d ∈N and consider A := (1, . . . , 1) ∈Z1×d, then the set M := {e1 −ei :\\n2 ≤i ≤d} is a Markov basis for the collection PA. However, M is not ∥·∥p-norm-reducing for\\nany d ≥3 and any p ∈[1, ∞]. For instance, consider e2 and e3 in FA,1 (M). The only move\\nfrom M that can be applied on e2 is e1−e2, but ∥(e2+e1−e2)−e3)∥p = ∥e2−e3∥p. On the other\\nhand, in the case we cannot ﬁnd a move that decreases the 1-norm of two nodes u, v ∈FA,b\\nby 1, we can ﬁnd instead two moves m1, m2 ∈M such that u + m1, u + m1 + m2 ∈FA,b and\\n∥u + m1 + m2 −v∥= ∥u −v∥−2. Thus, the graph-distance of any two elements u and v in\\nFA,b (M) is at most ∥u −v∥1 and hence M is norm-like for PA.\\nFigure 2. The graph from Example 3.4\\nRemark 3.6. Let P be a collection of ﬁnite subsets of Zd and M ⊂Zd be norm-like for P.\\nIt follows from the deﬁnition that there exists a constant C ∈Q≥0 such that for all F ∈P\\ndiam(F(M)) ≤C · max{∥u −v∥: u, v ∈F}.\\nThe proof of our next results uses the Graver basis GA ⊂Zd for an integer matrix A ∈Zm×d\\nwith kerZ(A) ∩Nd = {0}. We refer to [4, Chapter 3] for a precise deﬁnition.\\nProposition 3.7. Let A ∈Zm×d with kerZ(A) ∩Nd = {0} and M ⊂kerZ(A) be a Markov\\nbasis of PA. Then M is norm-like for PA.\\nProof. Let M be a Markov basis for PA. The Graver basis GA for A is a ﬁnite set which\\nis ∥· ∥1-norm-reducing for PA. Thus, deﬁne C := maxg∈GA diam(FA,Ag+ (M)). Now, pick\\nu, v ∈FA,b arbitrarily and let u = v + Pr\\ni=1 gi be a walk from u to v in FA,b (GA) of minimal\\nlength. Since the Graver basis is norm-reducing for FA,b, there always exists a path of length\\nat most ∥u −v∥1 and hence r ≤∥u −v∥1. Every gi can be replaced by a path in FA,Ag+\\ni (M)\\n6\\nCAPRICE STANLEY AND TOBIAS WINDISCH\\nof length at most C and these paths stay in FA,b. This gives a path of length C · r, hence\\ndistFA,b(M)(u, v) ≤C∥u −v∥1.\\n□\\nProposition 3.8. Let P ⊂Zd be a polytope with dim(P ∩Zd) > 0 and let M be a Markov\\nbasis for Fi := (i · P) ∩Zd for all i ∈N. There exists a constant C′ ∈Q>0 such that for all\\ni ∈N, C′ · i ≤diam(Fi(M)). If M is norm-like for {Fi : i ∈N}, then there exists a constant\\nC ∈Q>0 such that diam(Fi(M)) ≤C · i for all i ∈N.\\nProof. For the lower bound on the diameter, it suﬃces to show the existence of C′ such that\\nC′ · i ≤max{∥u −v∥: u, v ∈Fi} for all i ∈N due to Lemma 3.1. Since dim(P ∩Zd) > 0,\\nwe can pick distinct w, w′ ∈P ∩Zd. For all i ∈N, i · w, i · w′ ∈Fi and hence i · ∥w −w′∥≤\\nmax{∥u −v∥: u, v ∈Fi}.\\nTo show the upper bound, assume that M is norm-like. It suﬃces to show that there\\nexists C ∈Q≥0 such that max{∥u −v∥: u, v ∈Fi} ≤i · C by Remark 3.6.\\nNow, let\\nv1, . . . , vr ∈Qd such that P = convQ(v1, . . . , vr) and deﬁne C := max{∥vs −vt∥: s ̸= t}.\\nSince Fi = (i·P)∩Zd ⊂convQ(iv1, . . . , ivr) for all i ∈N, we have max{∥u−v∥: u, v ∈Fi} ≤\\nmax{∥ivs −ivt∥: s ̸= t} ≤C · i.\\n□\\nRemark 3.9. Let A ∈Zm×n with kerZ(A) ∩Nd = {0} and let M be a Markov basis for PA.\\nThen M is norm-like due to Proposition 3.7 and thus for all b ∈NA there exists C, C′ ∈Q≥0\\nsuch that\\ni · C′ ≤diam(FA,ib (M)) ≤i · C\\nfor all i ∈N. This generalizes for instance [20, Proposition 2.10] and [27, Example 4.7], where\\nlinear diameters on a ray in NA have been observed. This also implies that the construction\\nof expanders from [27, Section 4] works for every right-hand side b ∈NA.\\nRemark 3.10. Let A ∈Zm×d with kerZ(A)∩Nd = {0}, b ∈NA, and let M be a Markov basis\\nfor PA. Proposition 3.8 provides a new proof that the simple walk on (FA,ib (M))i∈N cannot\\nmix rapidly. The lower bound on the diameter from Proposition 3.8 implies, in general, the\\nfollowing upper bound on the edge-expansion (see for example [9, Proposition 1.30]):\\nh(FA,i·b (M)) ≤|M|\\n\\x12\\nexp\\n\\x12log |FA,i·b|\\nD · i\\n\\x13\\n−1\\n\\x13\\n.\\nIn particular, the edge-expansion cannot be bounded from below by Ω( 1\\np(i))i∈N for a polyno-\\nmial p ∈Q[t] and since (|FA,i·b|)i∈N ∈O(ir)i∈N, the simple walk cannot mix rapidly. In [27],\\nit was shown that the edge-expansion can be bounded from above by O(1\\ni )i∈N, which cannot\\nbe concluded from the upper expression.\\nWe now turn our attention to the diameter of compressed ﬁber graphs.\\nIn particular,\\nwe want to know for which collections of normal sets is their diameter bounded. In general,\\ncompressing a ﬁber graph does not necessarily have an eﬀect on the diameter (Example 3.11).\\nAlthough a low diameter is a necessary condition for good mixing, it is not suﬃcient. For\\ninstance, let Gn be the disjoint union of two complete graphs Kn connected by a single edge.\\nThen diam(Gn) = 3, but h(Gn) ≤1\\nn implies that the simple walk does not mix rapidly.\\nHEAT-BATH RANDOM WALKS WITH MARKOV BASES\\n7\\nExample 3.11. For any n ∈N, let Fn := {(0, 0), (0, 1), (1, 1), (1, 2), . . . , (n, n)} ⊂Z2. The\\nunit vectors M = {e1, e2} are a Markov basis for {Fn : n ∈N}. However, Fc\\nn(M) = Fn(M)\\nand thus diam(Fc\\nn(M)) = diam(Fn(M)) = 2n is unbounded.\\nLemma 3.12. Let A ∈Zm×d and z ∈kerZ(A). There exists r ∈[2d −2], distinct elements\\ng1, . . . , gr ∈GA, and λ1, . . . , λr ∈N>0 such that z = Pr\\ni=1 λigi and gi ⊑z for all i ∈[r]\\nProof. This is [4, Lemma 3.2.3], although it only becomes clear from the original proof of [22,\\nTheorem 2.1] that the appearing elements are all distinct.\\n□\\nProposition 3.13. Let A ∈Zm×d and P :=\\n\\x08\\n{x ∈Zd : Ax = b, l ≤x ≤u} : l, u ∈Zd, b ∈Zm\\t\\n.\\nThen for all F ∈P, diam(Fc(GA)) ≤2d −2.\\nProof. Let s, t ∈{x ∈Zd : Ax = b, l ≤x ≤u}, then s−t ∈kerZ(A) and thus s = t+Pr\\ni=1 λigi\\nwith r ≤2d −2, λ1, . . . , λr ∈N>0, and distinct g1, . . . , gr ∈GA such that gi ⊑s −t according\\nto Lemma 3.12. It’s now a consequence from [4, Lemma 3.2.4] that all intermediate points\\nt + Pk\\ni=1 λigi for k ≤r are in {x ∈Zd : Ax = b, l ≤x ≤u}.\\n□\\nLemma 3.14. Let F ⊂Zd be ﬁnite and let Fi := (i · convQ(F)) ∩Zd for i ∈N. For all\\nu, v ∈F, distFc\\ni (M)(iu, iv) ≤distF(M)(u, v) for all i ∈N.\\nProof. The statement is trivially true if u and v are disconnected in F(M). Thus, assume\\nthe contrary and let u = v + Pk\\nj=1 mj with mj ∈M be a path in F(M) of length k =\\ndistF(M)(u, v) and let i ∈N. Clearly, i · u = i · v + i · Pk\\nj=1 mj = i · v + Pk\\nl=1 i · mj, so\\nit is left to prove that the elements traversed by this paths are in Fi. Let l ∈[k], since\\nv + Pl\\nj=1 mj ∈F, we have i · v + Pl\\nj=1 i · mj ∈i · F ⊆Fi. Hence, this is a path in Fc\\ni (M)\\nof length k = distF(M)(u, v).\\n□\\nWe are ready to prove that the diameter of compressed ﬁber graphs coming from an integer\\nmatrix can be bounded for all right-hand sides simultaneously.\\nTheorem 3.15. Let A ∈Zm×d with kerZ(A) ∩Nd = {0} and let M be a Markov basis for\\nPA. There exists a constant C ∈N such that diam(Fc(M)) ≤C for all F ∈PA.\\nProof. Our proof relies on basic properties of the Graver basis GA of A. For any g ∈GA,\\nlet Fg := FA,Ag+ and let K := max{distFg(M)(g+, g−) : g ∈GA}.\\nWe show that the\\ndiameter of any compressed ﬁber graph of A is bounded from above by (2d −2) · K. Let\\nb ∈NA arbitrary and choose elements u, v ∈FA,b. According to Proposition 3.13, there\\nexists r ∈[2d −2], g1, . . . , gr ∈GA and λ1, . . . , λr ∈Z such that u = v + Pr\\ni=1 λigi, and\\nv + Pl\\ni=1 λigi ∈Nd for all l ∈[r].\\nAccording to Lemma 3.14, for any i ∈[r] there are\\nmi\\n1, . . . , mi\\nki ∈M and α1, . . . , αki ∈Z such that λig+\\ni = λig−\\ni + Pki\\nj=1 αjmi\\nj is a path in the\\ncompression of FA,Aλig+\\ni (M) of length ki ≤K. Lifting these paths for every i ∈[r] yields a\\npath u = v + Pr\\ni=1\\nPki\\nj=1 αjmi\\nj in Fc\\nA,b (M) of length r · K ≤(2d −2) · K.\\n□\\n8\\nCAPRICE STANLEY AND TOBIAS WINDISCH\\n4. Heat-bath random walks\\nIn this section, we establish the heat-bath random walk on compressed ﬁber graphs. We\\nrefer to [8] for a more general introduction on random walks of heat-bath type. Let F ⊂Zd\\nbe ﬁnite set. For any u ∈F and m ∈Zd, the ray in F through u along m is denoted by\\nRF,m(u) := (u + m · Z) ∩F. Additionally, given a mass function π : F →[0, 1], we deﬁne\\nHπ\\nF,m(x, y) :=\\n(\\nπ(y)\\nπ(RF,m(x))\\n, if y ∈RF,m(x)\\n0\\n, otherwise\\nfor x, y ∈F. For M ⊂Zd and a mass function f : M →[0, 1], the heat-bath random walk is\\n(4.1)\\nHπ,f\\nF,M =\\nX\\nm∈M\\nf(m) · Hπ\\nF,m.\\nThe underlying graph of the heat-bath random walk is the compression Fc(M) and in this\\nsection, we assume throughout that for all m ∈M and λ ∈Z \\\\ {−1, 1}, λ · m ̸∈M. Let us\\nﬁrst recall the basic properties of this random walk (compare also to [6, Lemma 2.2]).\\nAlgorithm 1 Heat-bath random walk on compressed ﬁber graphs\\nInput: F ⊂Zd, M ⊂Zd, v ∈F, mass functions f : M →[0, 1] and π : F →[0, 1], r ∈N\\n1: procedure HeatBath:\\n2:\\nv0 := v\\n3:\\nFOR s = 0; s = s + 1, s < r\\n4:\\nSample m ∈M according to f\\n5:\\nSample vs+1 ∈RF,m(vs) according to RF,m(vs) →[0, 1], y 7→\\nπ(y)\\nπ(RF,m(vs))\\n6:\\nRETURN v1, . . . , vr\\nProposition 4.1. Let F ⊂Zd and M ⊂Zd be ﬁnite sets. Let f : M →[0, 1] and π : F →\\n(0, 1) be mass functions. Then Hπ,f\\nF,M is aperiodic, has stationary distribution π, is reversible\\nwith respect to π, and all of its eigenvalues are non-negative. The random walk is irreducible\\nif and only if {m ∈M : f(m) > 0} is a Markov basis for F.\\nProof. Since for any u ∈F and any m ∈M, Hπ\\nF,m(u, u) > 0, there are halting states and\\nthus Hπ,f\\nF,M is aperiodic. By deﬁnition, π(x)Hπ\\nF,m(x, y) = π(y)Hπ\\nF,m(y, x) and thus Hπ,f\\nF,M\\nis reversible with respect to π and π is a stationary distribution.\\nThe statement on the\\neigenvalues is exactly [8, Lemma 1.2]. Let M′ = {m ∈M : f(m) > 0} and f ′ = f|M′, then\\nHπ,f\\nF,M = Hπ,f′\\nF,M′ and thus the heat-bath random walk is irreducible if and only if M′ is a\\nMarkov basis for F.\\n□\\nRemark 4.2. Analyzing the speed of convergence of random walks with second largest\\neigenvalues does not take the computation time of a single transition into account. From\\na computational point of view, the diﬀerence of the simple walk and the heat-bath random\\nwalk is Step 4 of Algorithm 1. However, we argue that Step 4 can be done eﬃciently in\\nmany cases. For instance, a hard normalizing constant of π cancels out. If π is the uniform\\ndistribution, then one needs to sample uniformly from RF,m(v) in Step 4, which can be done\\nHEAT-BATH RANDOM WALKS WITH MARKOV BASES\\n9\\neﬃciently. If the input of Algorithm 1 is a normal set F = {u ∈Zd : Au ≤b} that is given\\nin H-representation, then the length of the ray RF,m(v) can be computed with a number of\\nrounding, division, and comparing operations that is linear in the number of rows of A.\\nThere are situations in which the heat-bath random walk provides no speed-up compared\\nwith the simple walk (Example 4.3). Intuitively, adding more moves to the set of allowed\\nmoves should improve the mixing time of the random walk. In general, however, this is not\\ntrue for the heat-bath walk (Example 4.4).\\nExample 4.3. For n ∈N, consider the normal set\\nFn :=\\n\\x1a\\x14\\n0\\n1\\n1\\n· · ·\\n1\\n1\\n0\\n0\\n· · ·\\n0\\n\\x15\\n,\\n\\x14\\n1\\n0\\n1\\n· · ·\\n1\\n0\\n1\\n0\\n· · ·\\n0\\n\\x15\\n, . . . ,\\n\\x14\\n1\\n1\\n· · ·\\n1\\n0\\n0\\n0\\n· · ·\\n0\\n1\\n\\x15\\x1b\\n⊂Q2×n.\\nIn the language of [7, Section 1.1], Fn is precisely the ﬁber of the 2 × n independence model\\nwhere row sums are (n −1, 1) and column sums are (1, 1, . . . , 1).\\nThe minimal Markov\\nbasis of the independence model, often referred to as the basic moves, is precisely the set\\nMn := {v −u : u, v ∈Fn} \\\\ {0}. In particular, the ﬁber graph Fn(Mn) is the complete\\ngraph on n nodes. All rays along basic moves have length 2 and thus the transition matrices\\nof the simple random walk and the heat-bath random walk coincide. There are n · (n −1)\\nmany basic moves and the transition matrix of both random walks is\\n1\\nn(n −1)\\n\\uf8ee\\n\\uf8ef\\uf8f0\\n1\\n. . .\\n1\\n...\\n...\\n1\\n. . .\\n1\\n\\uf8f9\\n\\uf8fa\\uf8fb+ (n(n −1) −n)\\nn(n −1)\\n· In.\\nThe second largest eigenvalue is 1 −\\n1\\nn−1 which implies that for n →∞, neither the simple\\nwalk nor the heat-bath random walk are rapidly mixing.\\nExample 4.4. Let F = [2] × [5] ⊂Z2, M = {e1, e2, 2e1 + e2}, and let π be the uniform\\ndistribution on F.\\nSince {e2, 2e1 + e2} is not a Markov basis for F, any mass function\\nf : M →[0, 1] must have f(e1) > 0 in order to make the corresponding heat-bath random\\nwalk irreducible.\\nComparing the second largest eigenvalue modulus of heat-bath random\\nwalks that sample from {e1, e2} and M uniformly, we obtain\\nλ\\n\\x121\\n2Hπ\\nF,e1 + 1\\n2Hπ\\nF,e2\\n\\x13\\n= 1\\n2 < 2\\n3 = λ\\n\\x121\\n3Hπ\\nF,e1 + 1\\n3Hπ\\nF,e2 + 1\\n3Hπ\\nF,2e1+e2\\n\\x13\\n.\\nSo, adding 2e1 + e2 to the set of allowed moves slows the walk down. This phenomenon does\\nnot appear for the simple walk on F, where the second largest eigenvalue modulus improves\\nfrom ≈0.905 to ≈0.888 when adding the move 2e1 + e2 to the Markov basis.\\n=\\n+\\n+\\nFigure 3. Decomposition of the graph in Example 4.4\\n10\\nCAPRICE STANLEY AND TOBIAS WINDISCH\\nRemark 4.5. Let F ⊂Zd be ﬁnite and M = {m1, . . . , md} ⊂Zd be a linearly independent\\nMarkov basis of F. If the moves are selected uniformly, then the heat-bath random walk on\\nF coincides with the Glauber dynamics on F. To see it, choose u ∈F and let\\nF′ := {λ ∈Zd : u + λ1m1 + · · · + λdmd ∈F}.\\nIt is easy to check that F′ is unique up to translation and depends only on F, u, and M.\\nSince the vectors in M are linearly independent, every element of F can be represented by\\na unique choice of coeﬃcients in F′. Thus, the heat-bath random walk on F using M is\\nequivalent to the heat-bath random walk on on F′ using the unit vectors as moves. For any\\nunit vector ei ∈Zd, the ray through an element v ∈F′ is {w ∈F : wj = vj∀j ̸= i} and this\\nis precisely the form desired in the Glauber dynamics [14, Section 3.3.2].\\nFor the remainder of this section, we primarily focus on heat-bath random walks Hπ,f\\nF,M\\nthat converge to the uniform distribution π on a ﬁnite, but not necessarily normal, set\\nF. We particularly aim for bounds on its second largest eigenvalue by making use of the\\ndecomposition from equation 4.1. Our ﬁrst observations consider its summands Hπ\\nF,m that\\ncan be well understood analytically (Proposition 4.6) and combinatorially (Proposition 4.7).\\nProposition 4.6. Let F ⊂Zd be a ﬁnite set, m ∈Zd, and π : F →[0, 1] be the uniform\\ndistribution. Let R1, . . . , Rk be the disjoint rays through F along m. Then\\n1. Hπ\\nF,m is symmetric and idempotent.\\n2. img(Hπ\\nF,m) = spanR\\nnP\\nx∈R1 ex, P\\nx∈R2 ex, . . . , P\\nx∈Rk ex\\no\\n.\\n3. ker(Hπ\\nF,m) = Lk\\ni=1 spanR {ex −ey : x, y ∈Ri, x ̸= y}.\\n4. rank(Hπ\\nF,m) = k and dim ker(Hπ\\nF,m) = |F| −k.\\n5. The spectrum of Hπ\\nF,m is {0, 1}.\\nProof. Symmetry of Hπ\\nF,m follows from the deﬁnition. By assumption, F is the disjoint union\\nof R1, . . . , Rk and hence there exists a permutation matrix S such that SHπ\\nF,mST is a block\\nmatrix whose building blocks are the matrices\\n1\\n|Ri|\\n\\uf8ee\\n\\uf8ef\\uf8f0\\n1\\n. . .\\n1\\n...\\n...\\n1\\n. . .\\n1\\n\\uf8f9\\n\\uf8fa\\uf8fb∈Q|Ri|×|Ri|.\\nThus, Hπ\\nF,m is idempotent and the rank of Hπ\\nF,m is k. A basis of its image and its kernel can\\nbe read oﬀdirectly and idempotent matrices can only have the eigenvalues 0 and 1.\\n□\\nProposition 4.7. Let F ⊂Zd and M ⊂Zd be ﬁnite sets, π : F →[0, 1] be the uniform\\ndistribution, and let V1, . . . , Vc ⊆F be the nodes of the connected components of F(M), then\\n\\\\\\nm∈M\\nimg(Hπ\\nF,m) = spanR\\n\\uf8f1\\n\\uf8f2\\n\\uf8f3\\nX\\nx∈V1\\nex, . . . ,\\nX\\nx∈Vc\\nex\\n\\uf8fc\\n\\uf8fd\\n\\uf8fe.\\nProof. It is clear by Proposition 4.6 that the set on the right-hand side is contained in any\\nimg(Hπ\\nF,m) since any Vi decomposes disjointly into rays along m ∈M. To show the other\\ninclusion, write M = {m1, . . . , mk} and let for any i ∈[k], Ri\\n1, . . . , Ri\\nni be the disjoint rays\\nHEAT-BATH RANDOM WALKS WITH MARKOV BASES\\n11\\nthrough F parallel to mi. In particular, {Ri\\n1, . . . , Ri\\nni} is a partition of F for any i ∈[k]. Let\\nv ∈T\\nm∈M img(Hπ\\nF,m). Again by Proposition 4.6, there exists for any i ∈[k], λi\\n1, . . . , λi\\nni ∈Q\\nsuch that\\nv =\\nni\\nX\\nj=1\\nX\\nx∈Ri\\nj\\nλi\\njex.\\nNotice that if two distinct Markov moves mi and mi′ and two indices j ∈[ni] and j′ ∈[ni′]\\nsatisfy Ri\\nj ∩Ri′\\nj′ ̸= ∅, then λi\\nj = λi′\\nj′. We show that for any i ∈[k] and any a ∈[c], λi\\nj = λi\\nj′\\nwhen Ri\\nj and Ri\\nj′ are a subset of Va. This implies the proposition. So take distinct x, x′ ∈Va\\nand assume that x and x′ lie on diﬀerent rays of mi and let that be x ∈Ri\\nj and x′ ∈Ri\\nj′ with\\nj ̸= j′. Since x and x′ are in the same connected component Va of F(M), let yi0, . . . , yir ∈F\\nbe the nodes on a minimal path in Fc(M) with yi0 = x and yir = x′. For any s ∈[r], yis\\nand yis−1 are contained in the same ray Rks\\nts coming from a Markov move mks. In particular,\\nRts−1\\nks−1 ∩Rks\\nts ̸= ∅and due to our observation made above λi\\nj = λk1\\nt1 = λk2\\nt2 = · · · = λkr\\ntr = λi\\nj′\\nwhich ﬁnishes the proof.\\n□\\nDeﬁnition 4.8. Let F ⊂Zd and M ⊂Zd be ﬁnite sets and M′ ⊆M. Let V be the set of\\nconnected components of F(M\\\\M′) and R be the set of all rays through F along all elements\\nof M′. The ray matrix of F(M) along M′ is AF(M, M′) := (|R ∩V |)R∈R,V ∈V ∈NR×V.\\nExample 4.9. Let F = [3]×[3], M = {e1, e2, e1 +e2}, and M′ = {e1, e2}. Then F(M\\\\M′)\\nhas ﬁve connected components and the ray matrix of F(M) along M′ is\\nAF(M, M′) =\\n\\uf8ee\\n\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8f0\\n1\\n1\\n1\\n0\\n0\\n0\\n1\\n1\\n1\\n0\\n0\\n0\\n1\\n1\\n1\\n0\\n0\\n1\\n1\\n1\\n0\\n1\\n1\\n1\\n0\\n1\\n1\\n1\\n0\\n0\\n\\uf8f9\\n\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fb\\n.\\nRemark 4.10. Let F ⊂Z2, then the rays through F along e1 are the connected components\\nof F({e1, e2} \\\\ {e2}) and the rays through F along e2 are the connected components of\\nF({e1, e2} \\\\ {e1}), thus AF(M, e1) = AF(M, e2)T .\\nProposition 4.11. Let F ⊂Zd and M ⊂Zd be ﬁnite sets, π : F →[0, 1] be the uniform\\ndistribution, and M′ ⊆M. Then\\nker(AF(M, M′)) ∼=\\n\\\\\\nm∈M\\\\M′\\nimg(Hπ\\nF,m) ∩\\n\\\\\\nm∈M′\\nker(Hπ\\nF,m).\\nProof. Let V1, . . . , Vc be the connected components of F(M \\\\ M′) and R1, . . . , Rr be the\\nrays along elements in M′. Let I := T\\nm∈M\\\\M′ img(Hπ\\nF,m) and K := T\\nm∈M′ ker(Hπ\\nF,m). By\\nProposition 4.7, any element of I has the form v = Pc\\ni=1(λi\\nP\\nx∈Vi ex) for λ1, . . . , λc ∈Q.\\nAssume additionally that v ∈ker(Hπ\\nF,m) for m ∈M′ and let Ri1, . . . Rij be the rays which\\nbelong to m, then for any k ∈[j], 0 = P\\nx∈Rik vx = Pc\\nj=1 λj|Rik∩Vj|. Put diﬀerently, a vector\\nλ ∈Rc is in the kernel of (|Ri ∩Vj|)i∈[r],j∈[c] if and only if Pc\\ni=1(λi\\nP\\nx∈Vi ex) ∈I ∩K.\\n□\\n12\\nCAPRICE STANLEY AND TOBIAS WINDISCH\\nConditions on the kernel of the ray matrix allow us to give a lower bound on the second\\nlargest eigenvalue of the heat-bath random walk.\\nProposition 4.12. Let F ⊂Zd and M ⊂Zd be ﬁnite sets and π be the uniform distribution.\\nLet M′ ⊆M such that ker(AF(M, M′)) ̸= {0}, then λ(Hπ,f\\nF,M) ≥1 −P\\nm∈M′ f(m) for any\\nmass function f : M →[0, 1].\\nProof. Using the isomorphism from Proposition 4.11, we can choose a non-zero v ∈QP such\\nthat Hπ\\nF,mv = v for all m ∈M \\\\ M′ and Hπ\\nF,mv = 0 for all m ∈M′. In particular\\nHπ,f\\nF,Mv =\\nX\\nm∈M\\nf(m)Hπ\\nF,mv =\\nX\\nm∈M\\\\M′\\nf(m)Hπ\\nF,mv =\\nX\\nm∈M\\\\M\\nf(m)v.\\nSince f is a mass function, 1 −P\\nm∈M′ f(m) is an eigenvalue of Hπ,f\\nF,M.\\n□\\nDeﬁnition 4.13. Let F ⊂Zd and m, m′ ∈Zd not collinear.\\nThe pair (m, m′) has the\\nintersecting ray property in F if the following holds: For any pair of rays R1, R2 parallel\\nto m and any pair of rays R′\\n1, R′\\n2 parallel to m′ where both R1 ∩R′\\n1 and R2 ∩R′\\n2 are not\\nempty, then R1 ∩R′\\n2 ̸= ∅implies R′\\n1 ∩R2 ̸= ∅and |R1| · |R′\\n1|−1 = |R2| · |R′\\n2|−1. For a\\nﬁnite set M ⊂Zd, the graph Fc(M) has the intersecting ray property if all (m, m′) have the\\nintersecting ray property in F.\\nExample 4.14. The compressed ﬁber graph on [n1] × · · · × [nd] ⊂Zd that uses the unit\\nvectors {e1, . . . , ed} as moves has the intersecting ray property. On the other hand, consider\\nF = {u ∈N2 : u1 + u2 ≤1} and take the rays R1 := {(0, 0), (0, 1)} and R2 := {(1, 0)}\\nthat are parallel to e2 and the rays R′\\n1 := {(0, 1)} and R′\\n2 := {(0, 0), (1, 0)} that are parallel\\nto e1. Then R1 ∩R′\\n1 = {(1, 0)} and R2 ∩R′\\n2 = {(0, 1)}, but R1 ∩R′\\n2 = {(0, 0)} ̸= ∅and\\nR′\\n1 ∩R2 = ∅.\\nProposition 4.15. Let m, m′ ∈Zd not collinear and F ⊂Zd be a ﬁnite set. The matrices\\nHπ\\nF,m and Hπ\\nF,m′ commute if and only if (m, m′) have the intersecting ray property in F.\\nProof. Let u1, u2 ∈F. Then\\n(Hπ\\nF,m · Hπ\\nF,m′)u1,u2 =\\n(\\n|RF,m(u1)|−1 · |RF,m′(u2)|−1,\\nif RF,m(u1) ∩RF,m′(u2) ̸= ∅\\n0,\\notherwise\\n.\\nLet R1 := RF,m(u1), R′\\n1 := RF,m′(u1), R2 := RF,m(u2), and R′\\n2 := RF,m′(u2) Thus,\\n(Hπ\\nF,m · Hπ\\nF,m′)u1,u2 = (Hπ\\nF,m′ · Hπ\\nF,m)u1,u2. It is easy to see that the matrices commute if and\\nonly if (m, m′) have the intersecting ray property.\\n□\\nLemma 4.16. Let H1, . . . , Hn ∈Rn×n be pairwise commuting matrices. Then any eigenvalue\\nof Pn\\ni=1 Hi has the form λ1 + · · · + λn where λi is an eigenvalue of Hi.\\nProof. This is a straightforward extension of the case n = 2 in [12, Theorem 2.4.8.1] and\\nrelies on the fact that commuting matrices are simultaneously triangularizable.\\n□\\nHEAT-BATH RANDOM WALKS WITH MARKOV BASES\\n13\\nProposition 4.17. Let F ⊂Zd and M ⊂Zd be ﬁnite sets and suppose there exists m ∈M\\nsuch that (m, m′) has the intersecting ray property in F for all m′ ∈M′ := M \\\\ {m}. Let\\nV1, . . . , Vc be the connected components of F(M′), πi : Vi →[0, 1] the uniform distribution,\\nand f ′ = (1 −f(m))−1 · f|M′, then\\nλ(Hπ,f\\nF,M) ≤f(m) + (1 −f(m)) · max{λ(Hπi,f′\\nVi,M′) : i ∈[c]}.\\nProof. Let H := Hπ,f′\\nF,M′ be the heat-bath random walk on F(M) that samples moves from M′\\naccording to f ′, then Hπ,f\\nF,M = f(m)·Hπ\\nF,m +(1−f(m))·H. By assumption, all pairs (m, m′)\\nwith m′ ∈M′ have the intersecting ray property and thus the matrices Hπ\\nF,m and H commute\\naccording to Proposition 4.15. The eigenvalues of all involved matrices are non-negative and\\nthus Lemma 4.16 implies that the second largest eigenvalue of Hπ,f\\nF,M has the form λ + λ′\\nwhere λ ∈{0, f(m)} by Proposition 4.6 and where λ′ is an eigenvalue of (1 −f(m)) · H. The\\nmatrix H is a block matrix whose building blocks are the matrices Hπ,f′\\nVi,M′ = Hπi,f′\\nVi,M′ and thus\\nthe statement follows.\\n□\\nProposition 4.18. Let F ⊂Zd and M ⊂Zk be ﬁnite sets. If F(M) has the intersecting\\nray property, then λ(Hπ,f\\nF,M) ≤1 −min(f).\\nProof. Let M = {m1, . . . , mk}.\\nThe intersecting ray property and Proposition 4.15 give\\nthat the matrices f(m1) · Hπ\\nF,mi, . . . , f(mk) · Hπ\\nF,mk commute pairwise. According to Propo-\\nsition 4.6, the eigenvalues of f(mi) · Hπ\\nF,mi are {0, f(mi)}. Lemma 4.16 gives that the second\\nlargest eigenvalue of Hπ,f\\nF,M, which equals the second largest eigenvalue modulus since all of\\nits eigenvalues are non-negative, fulﬁlls λ(Hπ,f\\nF,M) = P\\ni∈I f(mi) for a subset I ⊆[k]. Since\\nλ(Hπ,f\\nF,M) < 1 and Pk\\ni=1 f(mi) = 1, we have I ̸= [k] and the claim follows.\\n□\\nProposition 4.19. Let n1, . . . , nd ∈N>1, F = [n1]×· · ·×[nd], and M = {e1, . . . , ed}. Then\\nfor any positive mass function f : M →[0, 1], λ(Hπ,f\\nF,M) = 1 −min(f).\\nProof. It is easy to verify that Fc(M) has the intersecting ray property and thus Proposi-\\ntion 4.18 shows λ(Hπ,f\\nF,M) ≤1−min(f). Assume that min(f) = f(ei). The connected compo-\\nnents of Fc({e1, . . . , ed} \\\\ {ei}) are the layers Vj := {u ∈F : ui = j} for any j ∈[ni] and the\\nrays through F parallel are Rk := {(0, k)+s·ei : s ∈[ni]} for k = (k1, . . . , ki−1, ki+1, . . . , kd) ∈\\n[n1] × · · · × [ni−1] × [ni+1] × · · · × [nd]. In particular, any ray intersects any connected com-\\nponent exactly once.\\nThus, the matrix (|Rk ∩Vj|)k,j is the all-ones matrix, which has a\\nnon-trivial kernel. Proposition 4.12 implies λ(Hπ,f\\nF,M) ≥1 −f(ei).\\n□\\nRemark 4.20. In the special case n := n1 = · · · = nd and f : {e1, . . . , ed} →[0, 1] the\\nuniform distribution in Proposition 4.19, the heat-bath random walk on [n]d is known as\\nRook’s walk in the literature. In this case, Proposition 4.19 is exactly [13, Proposition 2.3].\\nIn [18], upper bounds on the mixing time of the Rook’s walk were obtained with path-coupling.\\nThe stationary distribution of the heat-bath random walk is independent of the actual\\nmass function on the Markov moves. The problem of ﬁnding the mass function which leads\\n14\\nCAPRICE STANLEY AND TOBIAS WINDISCH\\nto the fastest mixing behaviour can be formulated as the following optimization problem:\\n(4.2)\\narg min\\n(\\nλ(Hπ,f\\nF,M) : f : M →(0, 1),\\nX\\nm∈M\\nf(m) = 1\\n)\\n.\\nIt follows from Proposition 4.19 that the optimal value of (4.2) for F = [n1] × · · · × [nd],\\nM = {e1, . . . , ed}, and the uniform distribution π on F is the uniform distribution on M.\\nAnother example where the uniform distribution is the optimal solution to (4.2), but where\\nthe veriﬁcation is more involved, is presented in Example 4.21.\\nExample 4.21. Let F = [2] × [5] as in Example 4.4 and consider M = {e1, 2e1 + e2}. We\\ninvestigate for which µ ∈(0, 1), the transition matrix µHπ\\nF,e1 + (1 −µ)Hπ\\nF,2e1+e2 has the\\nsmallest second largest eigenvalue modulus. Its characteristic polynomial in Q[µ, x] is\\n−1\\n25x4(x −1)(µ + x −1)6(−5x2 + 5x + 2µ2 −2µ)(−5x2 + 5x + 4µ2 −4µ)\\nand hence its eigenvalues are\\nx1(µ) := 1,\\nx2(µ) := 1 −µ,\\nx3(µ) := 1\\n2\\n\"\\n1 +\\nr\\n1 + 8\\n5(µ2 −µ)\\n#\\n,\\nx4(µ) := 1\\n2\\n\"\\n1 −\\nr\\n1 + 8\\n5(µ2 −µ)\\n#\\n,\\nx5(µ) := 1\\n2\\nh\\n1 +\\np\\n1 + 4(µ2 −µ)\\ni\\n,\\nx6(µ) := 1\\n2\\nh\\n1 −\\np\\n1 + 4(µ2 −µ)\\ni\\n.\\nIt is straightforward to check that x5(µ) > 1\\n2 > x6(µ), x3(µ) > 1\\n2 > x4(µ). Since µ2 −µ < 0\\nfor u ∈(0, 1) and x3(µ) ≥x6(µ). We can show that x4(µ) ≥x2(µ) and thus\\nλ(µHπ\\nF,e1 + (1 −µ)Hπ\\nF,2e1+e2) = 1\\n2\\n\"\\n1 +\\nr\\n1 + 8\\n5(µ2 −µ)\\n#\\n.\\nThe fastest heat-bath random walk on F(M) which converges to uniform is thus obtained for\\nµ = 1\\n2, i.e. when the moves are selected uniformly. The second largest eigenvalue in this case\\nis\\n1\\n10(5 +\\n√\\n15) ≈0.887, which is larger than the second largest eigenvalue of the heat-bath\\nwalk that selects uniformly from {e1, e2} (see Proposition 4.19).\\n5. Augmenting Markov bases\\nIt follows from our investigation in Section 3 that the diameter of all compressed ﬁber\\ngraphs coming from a ﬁxed integer matrix A ∈Zm×d can be bounded from above by a\\nconstant. However, Markov moves can be used twice in a minimal path which can make the\\ndiameter of the compressed ﬁber graph larger than the size of the Markov basis. The next\\ndeﬁnition puts more constraints on the Markov basis and postulates the existence of a path\\nthat uses every move from the Markov basis at most once.\\nDeﬁnition 5.1. Let F ⊂Zd be a ﬁnite set and M = {m1, . . . , mk} ⊂Zd. An augmenting\\npath between distinct u, v ∈F of length r ∈N is a path in Fc(M) of the form\\nu →u + λi1mi1 →u + λi1mi1 + λi2mi2 →· · · →u +\\nr\\nX\\nk=1\\nλikmik = v\\nHEAT-BATH RANDOM WALKS WITH MARKOV BASES\\n15\\nwith distinct indices i1, . . . , ir ∈[k]. An augmenting path is minimal for u, v ∈F if there\\nexists no shorter augmenting path between u and v in Fc(M).\\nA Markov basis M for\\nF is augmenting if there is an augmenting path between any distinct nodes in F.\\nThe\\naugmentation length AM(F) of an augmenting Markov basis M is the maximum length of\\nall minimal augmenting paths in Fc(M).\\nNot every Markov basis is augmenting (see Example 3.11), but the diameter of compressed\\nﬁber graphs that use an augmenting Markov basis is at most the number of the moves. For\\nﬁber graphs coming from an integer matrix, an augmenting Markov basis for all of its ﬁbers\\ncan be computed (Remark 5.2).\\nRemark 5.2. Let A ∈Zm×d with kerZ(A) ∩Nd = {0} and let b ∈NA. The Graver basis\\nis an augmenting Markov basis for FA,b for any b ∈NA. We claim that when A is totally\\nunimodular, then AGA(FA,b) ≤d2(rank(A) + 1).\\nIn particular, the augmentation length\\nis independent of the right-hand side b.\\nLet u, v ∈FA,b be arbitrary and for i ∈N, let\\nli := min{ui, vi}, wi := max{ui, vi}, and ci := sign(ui −vi) ∈{−1, 0, 1}. Then v is the unique\\noptimal value of the linear integer optimization problem\\nmin{cT x : Ax = b, l ≤x ≤w, x ∈Zd}.\\nA discrete steepest decent as deﬁned in [5, Deﬁnition 3] using Graver moves needs at most\\n∥c∥1 · d · (rank(A) + 1) ≤d2 · (rank(A) + 1) many augmentations from u to reach the optimal\\nvalue v. We refer to [5, Corollary 8] which ensures that every Graver move is used at most\\nonce. Note that in [5], x is constrained to x ≥0 instead to x ≥l, but their argument works\\nfor any lower bound.\\nExample 5.3. Fix d ∈N and consider A and M from Example 3.5. We show that M is an\\naugmenting Markov basis for FA,b for any b ∈N. Let u, v ∈FA,b be distinct, then there exists\\ni ∈[d] such that ui > vi or ui < vi, thus, we can walk from u to u′ := u + (ui −vi)(e1 −ei)\\nor from v to v′ := v + (vi −ui)(e1 −ei). In any case, after that augmentation, the pairs\\n(u′, v) and (v′, u) coincide in the ith coordinate and thus we ﬁnd an augmenting path by\\ninduction on the dimension d. We have used at most d −1 many edges in these paths and\\nhence AM(FA,b) ≤d −1 for all b ∈N.\\nWe now show that the augmentation length is essentially bounded from below by the\\ndimension of the node set and hence the bound observed in Example 5.3 cannot be improved.\\nWe ﬁrst need the following lemma.\\nLemma 5.4. Let v1, . . . , vk ∈Qd such that any v ∈spanQ {v1, . . . , vk} can be represented by\\na linear combination of r vectors. Then dim(spanQ {v1, . . . , vk}) ≤r.\\nProof. Let B ⊂P(v1, . . . , vk) the set of all subsets of cardinality r. By our assumption,\\n∪B∈BspanQ {B} = spanQ {v1, . . . , vk}. Since dim(spanQ {B}) ≤r for all B ∈B and since B\\nis ﬁnite, the claim follows.\\n□\\nProposition 5.5. Let P ⊂Qd be polytope and let M ⊂Zd be an augmenting Markov basis\\nfor Fi := (i · P) ∩Zd for all i ∈N. Then dim(P) ≤maxi∈N AM(Fi).\\n16\\nCAPRICE STANLEY AND TOBIAS WINDISCH\\nProof. Without restricting generality, we can assume that 0 ∈P. Let V := spanQ {P} be\\nthe Q-span of P, then dim(P) = dim(V ). We must have dim(spanQ {M}) = dim(V ) since\\ndim(P) = dim(convQ(Fi)) for i suﬃciently large and since M is a Markov basis for Fi. Deﬁne\\nr := maxi∈N AM(Fi) and choose any non-zero v ∈V and u ∈relint(P) ⊂Qd. Then there\\nexists δ ∈Q>0 such that u + δv ∈P. Thus, 1\\nδu + v ∈1\\nδP. Let c ∈N≥1 such that i := c\\nδ ∈N\\nand w := c\\nδu ∈Zd. Then w + cv = c(1\\nδ u + v) ∈(i · P) ∩Zd = Fi. By assumption, there exists\\nan augmenting path from w to w + cv using only r elements from M. Put diﬀerently, the\\nelement cv from V can be represented by a linear combination of r vectors from M. Since v\\nwas chosen arbitrarily, Lemma 5.4 implies dim(P) = dim(V ) ≤r.\\n□\\nRemark 5.6. It is a consequence from Proposition 5.5 that for any matrix A ∈Zm×d with\\nkerZ(A) ∩Nd = {0} and an augmenting Markov basis M, there exists F ∈PA such that\\nAM(F) ≥dim(kerZ(A)).\\nLet us now shortly recall the framework from [23] which is necessary to prove our main\\ntheorem. Let G = (V, E) be a graph. For any ordered pair of distinct nodes (x, y) ∈V × V ,\\nlet px,y ⊆E be a path from x to y in G and let Γ := {px,y : (x, y) ∈V × V, x ̸= y} be\\nthe collection of these paths, then Γ is a set of canonical paths. Let for any edge e ∈E,\\nΓe := {p ∈Γ : e ∈p} be the set of paths from Γ that use e. Now, let H : V × V →[0, 1] be a\\nsymmetric random walk on G and deﬁne\\nρ(Γ, H) := max{|p| : p ∈Γ}\\n|V |\\n· max\\n{u,v}∈E\\n|Γ{u,v}|\\nH(u, v).\\nObserve that symmetry of H is needed to make ρ(Γ, H) well-deﬁned. This can be used to\\nprove the following upper bound on the second largest eigenvalue.\\nLemma 5.7. Let G be a graph, H be a symmetric random walk on G, and Γ be a set of\\ncanonical paths in G. Then λ2(H) ≤1 −\\n1\\nρ(Γ,H).\\nProof. The stationary distribution of H is the uniform distribution and thus the statement\\nis a direct consequence of [23, Theorem 5], since ρ(Γ, H) is an upper bound on the constant\\ndeﬁned in [23, equation 4].\\n□\\nTheorem 5.8. Let F ⊂Zd be ﬁnite and let M := {m1, . . . , mk} ⊂Zd be an augmenting\\nMarkov basis. Let π be the uniform and f be a positive distribution on F and M respectively.\\nFor i ∈[k], let ri := max{|RF,mi(u)| : u ∈F} and suppose that r1 ≥r2 ≥· · · ≥rk. Then\\nλ(Hπ,f\\nM,F) ≤1 −\\n|F| · min(f)\\nAM(F) · AM(F)! · 3AM(F)−1 · 2|M| · r1r2 · · · rAM(F)\\n.\\nProof. Choose for any distinct u, v ∈F an augmenting path pu,v of minimal length in Fc(M)\\nand let Γ be the collection of all these paths. Let u + µmk = v be an edge in Fc(M), then\\nour goal is to bound |Γ{u,v}| from above. Let S := {S ⊆[r] : |S| ≤AM(F), k ∈S} and take\\nany path px,y ∈Γ{u,v}. Then there exists S := {i1, . . . , is} with s := |S| ≤AM(F) such that\\nx + Ps\\nk=1 λikmik = y. Since px,y uses the edge {u, v}, there is j ∈[s] such that ij = k and\\nλij = µ. Since |λik| ≤rik, there are at most\\ns! · (2ri1 + 1) · · · (2rij−1 + 1) · (2rij+1 + 1) · · · (2ris + 1) ≤s! · 3s−1\\nY\\nt∈S\\\\{k}\\nrt\\nHEAT-BATH RANDOM WALKS WITH MARKOV BASES\\n17\\npaths in Γ{u,v} that uses the edge {u, v} and the moves mi1, . . . , mij−1, mij+1 . . . , mis. Since\\nall the paths are minimal, they have length at most AM(F) so indeed every path in Γ has\\nthat form.\\n|Γu,v|\\nHπ,f\\nF,M(u, v)\\n≤3AM(F)−1\\nP\\nS∈S\\n\\x10\\n|S|! Q\\nt∈S\\\\{k} rt\\n\\x11\\nf(mij) ·\\n1\\n|Rmij (u)|\\n≤3AM(F)−1 · AM(F)! · |S| · r1r2 . . . rAM(F)\\nf(mij)\\n,\\nwhere we have used the assumption r1 ≥r2 ≥· · · ≥rk. Bounding |S| rigorously from above\\nby 2|M|, the claim follows from Lemma 5.7.\\n□\\nDeﬁnition 5.9. Let F ⊂Zd and M ⊂Zd be ﬁnite sets. The longest ray through F along\\nvectors of M is RF,M := arg max{|RF,m(u)| : m ∈M, u ∈F}.\\nCorollary 5.10. Let (Fi)i∈N be a sequence of ﬁnite sets in Zd and let πi be the uniform\\ndistribution on Fi. Let M ⊂Zd be an augmenting Markov basis for Fi with AM(Fi) ≤\\ndim(Fi) and suppose that (|RFi,M|)dim(Fi))i∈N ∈O(|Fi|)i∈N.\\nThen for any positive mass\\nfunction f : M →[0, 1], there exists ǫ > 0 such that λ(Hπi,f\\nFi,M) ≤1 −ǫ for all i ∈N.\\nProof. This is a straightforward application of Theorem 5.8.\\n□\\nCorollary 5.11. Let P ⊂Zd be a polytope, Fi := (i · P) ∩Zd for i ∈N, and let πi be the\\nuniform distribution on Fi. Suppose that M ⊂Zd is an augmenting Markov basis {Fi : i ∈N}\\nsuch that AM(Fi) ≤dim(P) for all i ∈N. Then for any positive mass function f : M →[0, 1],\\nthere exists ǫ > 0 such that λ(Hπi,f\\nFi,M) ≤1 −ǫ for all i ∈N.\\nProof. Let r := dim(P). We ﬁrst show that (|RFi,M|)i∈N ∈O(i)i∈N. Write M = {m1, . . . , mk}\\nand denote by li := max{|(u + mi · Z) ∩P| : u ∈P} be the length of the longest ray through\\nthe polytope P along mi. It suﬃces to prove that i · (lk + 1) is an upper bound on the\\nlength of any ray along mk through Fi. For that, let u ∈Fi such that u + λmk ∈Fi for\\nsome λ ∈N, then 1\\ni u + λ\\ni mk ∈P and thus ⌊λ\\ni ⌋≤lk, which gives λ ≤i · (lk + 1). With\\nC := max{l1, . . . , lk} + 1 we have |RFi,M| ≤C · i. Ehrhart’s theorem [2, Theorem 3.23]\\ngives (|Fi|)i∈N ∈Ω(ir)i∈N and since |RFi,M| ≤C · i, we have (|RFi,M|r)i∈N ∈O(|Fi|)i∈N. An\\napplication of Corollary 5.10 proves the claim.\\n□\\nExample 5.12. Fix d, r ∈N and let Cd,r := {u ∈Zd : ∥u∥1 ≤r} be the set of integers of the\\nd-dimensional cross-polytope with radius r. The set Md = {e1, . . . , ed} is a Markov basis for\\nCd,r for any r ∈N. We show that Md is an augmenting Markov basis whose augmentation\\nlength is at most d. For that, let u, v ∈Cd,r distinct elements. We claim that there exists\\ni ∈[d] such that xi ̸= vi and ui + (vi −ui) ∈Cd,r. Let S ⊆[d] be the set of indices where u\\nand v diﬀer and let s = r −||u||1. If |S| = 1, then the result is clear so suppose |S| ≥2. If\\nthe result doesn’t hold then for all i ∈S, |vi| −|ui| > s. It follows that\\n∥v∥1 =\\nX\\ni/∈S\\n|ui| +\\nX\\ni∈S\\n|vi| >\\nX\\ni/∈S\\n|ui| +\\nX\\ni∈S\\ns + |ui| = |Suv| · s + ∥u∥1 = (|S| −1) · s + r.\\nBut we assumed that v ∈Cd,r. It follows that for any pair of points u, v in Cd,r, there is a\\nwalk, using the unit vectors as moves, that uses each move at most once. Corollary 5.10 yield\\nthat for any d ∈N, the second largest eigenvalue modulus of the heat-bath random walk on\\nCd,r with uniform as stationary distribution can be strictly bounded away from 1 for r →∞.\\n18\\nCAPRICE STANLEY AND TOBIAS WINDISCH\\nThe bound on the second largest eigenvalue in Theorem 5.8 is quite general and can be\\nimproved vastly, provided one has better control over the paths. For example, this can be\\nachieved for hyperrectangles intersected with a halfspace.\\nProposition 5.13. Let a ∈Nd\\n>0, b ∈N, F = {u ∈Nd : aT · u ≤b}, and M := {e1, . . . , ed}.\\nIf π and f are the uniform distributions on F and M respectively, then\\nλ(Hπ,f\\nF,M) ≤1 −|F|\\nd2\\nd\\nY\\ni=1\\nai\\nb .\\nProof. Observe that M is a Markov basis for F since all nodes are connected with 0 ∈F.\\nLet u, v ∈F be distinct. We ﬁrst show that there exists k ∈[d] such that uk ̸= vk and\\nu + (vk −uk)ek ∈F. If u ≤v, the statement trivially holds. Otherwise, there exists k ∈[d]\\nsuch that uk > vk and the vector obtained by replacing the kth coordinate of u by vk remains\\nin F. Now, consider for the following path between u and v: Choose the smallest index\\nk ∈[d] such that uk ̸= vk and such that u + (vk −uk) · ek ∈F and proceed recursively with\\nu + (vk −uk) and v. This gives a path pu,v between u and v of length at most d. Let Γ be\\nthe collection of all these paths. We want to apply Lemma 5.7. Thus, let x ∈F and consider\\nthe edge x →x + c · es. Let us count the paths pu,v that use that edge. Let u, v ∈F and let\\nk1, . . . , kr ∈[d] be distinct indices such that\\nu →u + (vk1 −uk1)ek1 →u + (vk1 −uk1)ek1 + (vk2 −uk2)ek2 →· · · →v\\nrepresents the path pu,v constructed by the upper rule.\\nAssume that pu,v uses the edge\\n{x, x + ces} and let kl = s and (vkl −ukl) = c. In particular,\\nu + (vk1 −uk1)ek1 + · · · + (vkl−1 −ukl−1)ekl−1 = x\\nx + (vkl −ukl)ekl + · · · + (vkr −ukr)ekr = v.\\nWe see that vkt = xkt for all t < l and that ukt = xkt for all t ≥l. In particular, vkl =\\nukl + c = xkl + c is also ﬁxed. The coordinates ukt and vkt are bounded from above by\\nb\\nakt\\nfor all t ∈[r], and hence there can be at most\\n l−1\\nY\\nt=1\\nb\\nakt\\n!\\n·\\n \\nr\\nY\\nt=l+1\\nb\\nakt\\n!\\n.\\nSince k1, . . . , kt are distinct coordinate indices, we have\\n|Γx,x+c·es|\\nHπ,f\\nF,M(x, x + c · es)\\n≤d ·\\nd\\nY\\ni=1\\nb\\nai\\n.\\nLemma 5.7 ﬁnishes the proof.\\n□\\nIn ﬁxed dimension, Proposition 5.13 leads to rapid mixing, but for d →∞, no statement\\ncan be made. In [19], it was shown that the simple walk with an additional halting probability\\non {u ∈Nd : atu ≤b} ∩{0, 1}d has mixing time in O(d4.5+ǫ). For zero-one polytopes, simple\\nand heat-bath walk coincide and we are conﬁdent that a similar statement holds without the\\nrestriction on zero-one polytopes.\\nHEAT-BATH RANDOM WALKS WITH MARKOV BASES\\n19\\nThe heat-bath random walk mixes rapidly when an augmenting Markov basis with a small\\naugmentation length is used.\\nWe think that it is interesting to question how might an\\naugmenting Markov bases be obtained and how their augmentation length can be improved.\\nQuestion 5.14. Let M be an augmenting Markov basis of A. Can we ﬁnd ﬁnitely many\\nmoves m1, . . . , mk such that the augmentation length of M∪{m1, . . . , mk} on FA,b is at most\\ndim(kerZ(A)) for all b ∈NA?\\nReferences\\n1. Stephen Baumert, Archis Ghate, Seksan Kiatsupaibul, Yanfang Shen, Robert L. Smith, and Zelda B.\\nZabinsky, Discrete Hit-and-Run for Sampling Points from Arbitrary Distributions Over Subsets of Integer\\nHyperrectangles, Operations Research 57 (2009), no. 3, 727–739.\\n2. Matthias Beck and Sinai Robins, Computing the Continuous Discretely, Springer, New York, 2007.\\n3. Mary Cryan, Martin Dyer, Leslie Ann Goldberg, Mark Jerrum, and Russell Martin, Rapidly Mixing\\nMarkov Chains for Sampling Contingency Tables with a Constant Number of Rows, SIAM Journal on\\nComputing 36 (2006), no. 1, 247–278.\\n4. Jes´us A. De Loera, Raymond Hemmecke, and Matthias K¨oppe, Algebraic and Geometric Ideas in the\\nTheory of Discrete Optimization, MPS-SIAM Series on Optimization, SIAM, Cambridge, 2013.\\n5. Jes´us A. De Loera, Raymond Hemmecke, and Jon Lee, On Augmentation Algorithms for Linear and\\nInteger-Linear Programming: From Edmonds–Karp to Bland and Beyond, SIAM Journal on Optimization\\n25 (2015), no. 4, 2494–2511.\\n6. Persi Diaconis and Bernd Sturmfels, Algebraic algorithms for sampling from conditional distributions, The\\nAnnals of statistics 26 (1998), no. 1, 363–397.\\n7. Mathias Drton, Bernd Sturmfels, and Seth Sullivant, Lectures on algebraic statistics, Oberwolfach Semi-\\nnars, vol. 39, Springer, Berlin, 2009, A Birkh¨auser book.\\n8. Martin Dyer, Catherine Greenhill, and Mario Ullrich, Structure and eigenvalues of heat-bath Markov\\nchains, Linear Algebra and its Applications 454 (2014), 57–71.\\n9. Giles Gardam, Expander Graphs and Kazhdan’ s Property (T), Bachelor’s thesis, University of Sidney,\\n2012.\\n10. Hisayuki Hara, Akimichi Takemura, and Ruriko Yoshida, On connectivity of ﬁbers with positive marginals\\nin multiple logistic regression, Journal of Multivariate Analysis (2010), 1–26.\\n11. Raymond Hemmecke and Peter N. Malkin, Computing generating sets of lattice ideals and Markov bases\\nof lattices, Journal of Symbolic Computation 44 (2009), no. 10, 1463–1476.\\n12. Roger A. Horn, Matrix Analysis, 2nd ed., Cambridge University Press, New York, 2013.\\n13. Steven S. Kim, Mixing Time of a Rook’s Walk, Undergraduate certiﬁcate paper (2012).\\n14. David A. Levin, Yuval Peres, and Elisabeth L. Wilmer, Markov chains and mixing times, American\\nMathematical Society, Providence, RI, 2009.\\n15. L´aszl´o Lov´asz, Hit-and-run mixes fast, Mathematical Programming 86 (1999), no. 3, 443–461.\\n16. L´aszl´o Lov´asz and Santosh Vempala, Hit-and-Run from a Corner, SIAM Journal on Computing 35 (2006),\\nno. 4, 985–1005.\\n17. Peter N. Malkin, Computing Markov bases, Gr¨obner bases, and extreme rays, Phd thesis, 2007, p. 223.\\n18. Cam McLeman, Peter T. Otto, John Rahmani, and Matthew Sutter, Mixing times for the Rook’s walk\\nvia path coupling, to appear in Involve (2016), 1–12.\\n19. Ben Morris and Alistair Sinclair, Random Walks on Truncated Cubes and Sampling 0-1 Knapsack Solutions,\\nSIAM Journal on Computing 34 (2004), no. 1, 195–226.\\n20. Samu Potka, Higher connectivity of ﬁber graphs of Gr¨obner bases, Journal of Algebraic Statistics 4 (2013),\\nno. 1, 93–107.\\n21. Johannes Rauh and Seth Sullivant, Lifting Markov bases and higher codimension toric ﬁber products,\\nJournal of Symbolic Computation 74 (2016), 276–307.\\n22. Andr´as Seb¨o, Hilbert Bases, Caratheodory’s Theorem and Combinatorial Optimization, (1990), 431–455.\\n20\\nCAPRICE STANLEY AND TOBIAS WINDISCH\\n23. Alistair Sinclair, Improved Bounds for Mixing Rates of Markov Chains and Multicommodity Flow, Com-\\nbinatorics, Probability and Computing 1 (1992), no. 4, 351–370.\\n24. Bernd Sturmfels, Gr¨obner bases and convex polytopes, American Mathematical Society, Providence, R.I.,\\n1996.\\n25. Seth Sullivant, Markov bases of binary graph models, Annals of Combinatorics 7 (2003), 441–466.\\n26. Santosh S. Vempala, Geometric Random Walks: A Survey, MSRI Combinatorial and Computational\\nGeometry 52 (2005), 573–612.\\n27. Tobias Windisch, Rapid mixing and Markov bases, preprint, arXiv:1505.03018 (2015), 1–18.\\nNC State University, Raleigh, NC 27695, USA\\nE-mail address: crstanl2@ncsu.edu\\nOtto-von-Guericke Universit¨at, Magdeburg, Germany\\nE-mail address: windisch@ovgu.de\\n')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
